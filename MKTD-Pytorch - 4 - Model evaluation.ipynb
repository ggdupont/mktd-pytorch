{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices\n",
    "With each exercice will teach you one aspect of deep learning. The process of machine learning can be decompose in 7 steps :\n",
    "\n",
    "* Data preparation\n",
    "* Model definition\n",
    "* Model training\n",
    "* Model evaluation\n",
    "* Hyperparameter tuning\n",
    "* Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Model evaluation\n",
    "\n",
    "- 4.1 Visualize metrics during training (matplot)\n",
    "- 4.2 Detect overfitting / underfitting\n",
    "- 4.2 Validate model with unseen dataset\n",
    "- 4.3 Visualize confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(images, labels):\n",
    "    npimg = images.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(\"Ground Truth: {}\".format(labels))\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = './data'\n",
    "\n",
    "#trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=data_path, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=data_path, train=False, transform=trans, download=True)\n",
    "\n",
    "batch = 4\n",
    "\n",
    "data_train_loader = DataLoader(train_set, batch_size=batch, shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(test_set, batch_size=batch, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load leNet & co."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leVieuxNet = Net()\n",
    "optimizer = optim.SGD(leVieuxNet.parameters(), lr=0.01)\n",
    "\n",
    "checkpoint = torch.load('checkpoint-MKTD-pytorch-3.last')\n",
    "leVieuxNet.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(test_data, network):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            images, labels = data\n",
    "            outputs = network(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 96.870%\n"
     ]
    }
   ],
   "source": [
    "acc = compute_accuracy(data_test_loader, leVieuxNet)\n",
    "            \n",
    "print('Accuracy of the network on the {} test images: {:.3f}%'.format(len(data_test_loader), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a new net with another loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "leNet = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(leNet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_data, max_epoch):\n",
    "\n",
    "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_data):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(images)\n",
    "\n",
    "            # align vectors labels <=> outputs\n",
    "#             label_vect = torch.zeros(outputs.shape[0], outputs.shape[1], dtype=torch.long)\n",
    "#             for j in range(0, len(labels)):\n",
    "#                 label_vect[j, labels[j]] = 1.0 \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('[{:d}] loss: {:.5f}'.format(epoch + 1, running_loss / (batch*len(train_data))))\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.09175\n",
      "[2] loss: 0.01689\n",
      "[3] loss: 0.01207\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(leNet, criterion, optimizer, data_train_loader, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 98.280%\n"
     ]
    }
   ],
   "source": [
    "acc = compute_accuracy(data_test_loader, leNet)\n",
    "            \n",
    "print('Accuracy of the network on the {} test images: {:.3f}%'.format(len(data_test_loader), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing another gradient descent variant\n",
    "\n",
    "http://ruder.io/optimizing-gradient-descent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.03603\n",
      "[2] loss: 0.02040\n",
      "[3] loss: 0.01881\n",
      "Finished Training\n",
      "Accuracy of the network on the 2500 test images: 98.090%\n"
     ]
    }
   ],
   "source": [
    "leNet = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(leNet.parameters(), lr=2e-3)\n",
    "train(leNet, criterion, optimizer, data_train_loader, 3)\n",
    "acc = compute_accuracy(data_test_loader, leNet)\n",
    "            \n",
    "print('Accuracy of the network on the {} test images: {:.3f}%'.format(len(data_test_loader), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of 0: 98.775510%\n",
      "Precision of 1: 99.207048%\n",
      "Precision of 2: 97.383721%\n",
      "Precision of 3: 96.732673%\n",
      "Precision of 4: 99.389002%\n",
      "Precision of 5: 98.654709%\n",
      "Precision of 6: 97.807933%\n",
      "Precision of 7: 99.124514%\n",
      "Precision of 8: 96.919918%\n",
      "Precision of 9: 96.828543%\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in data_test_loader:\n",
    "        images, labels = data\n",
    "        outputs = leNet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Precision of {:s}: {:2f}%'.format(classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Visualize confusion matrix\n",
    "- play with batch size, epoch\n",
    "- Visualize metrics during training (matplot)\n",
    "- Detect overfitting / underfitting\n",
    "- stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mktd-pytorch",
   "language": "python",
   "name": "mktd-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
