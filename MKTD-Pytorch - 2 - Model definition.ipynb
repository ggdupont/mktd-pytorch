{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices\n",
    "\n",
    "With each exercice will teach you one aspect of deep learning.\n",
    "The process of machine learning can be decompose in 7 steps :\n",
    "\n",
    "0. Data acquisition\n",
    "1. Data preparation\n",
    "2. Model definition\n",
    "3. Model training\n",
    "4. Model evaluation\n",
    "5. Hyperparameter tuning\n",
    "6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Model definition\n",
    "\n",
    "from https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "#### Initialization of tensors\n",
    "\n",
    "Tensors are just super matrix, and it's easy to play with these in pytorch (some say easier than ndarray in pandas...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -1.5846e+29, -1.5244e+07],\n",
      "        [-1.0845e-19,  5.5481e-20,  1.4013e-45],\n",
      "        [ 1.0031e-28,  4.0178e-41,  1.0031e-28],\n",
      "        [ 4.0178e-41,  8.3451e-10,  1.6899e-04],\n",
      "        [-4.2569e-06,  4.5845e-41, -1.5236e+07]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7582, 0.4262, 0.6134],\n",
      "        [0.0238, 0.1727, 0.9239],\n",
      "        [0.7537, 0.7834, 0.0335],\n",
      "        [0.7128, 0.3169, 0.2428],\n",
      "        [0.4421, 0.7118, 0.6120]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.0097,  1.4601,  0.5915],\n",
      "        [-0.1474,  1.7640, -1.4440],\n",
      "        [-0.2559,  1.0191,  0.3020],\n",
      "        [ 1.4006, -2.3740, -1.3858],\n",
      "        [-0.5092,  0.3114, -1.2601]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors operations\n",
    "\n",
    "Generate tensors and apply operations to get things done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2923,  2.0582,  2.3664],\n",
      "        [-2.0153,  2.2022, -0.4129],\n",
      "        [-1.3965,  1.8661,  1.2686],\n",
      "        [ 1.5011, -0.7045, -2.4005],\n",
      "        [ 0.3618, -0.8300, -1.6199]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn_like(x, dtype=torch.float) \n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2729,  0.8620, -1.1833],\n",
      "        [ 1.7205,  1.3259, -2.4751],\n",
      "        [ 0.8846,  0.1721, -0.6645],\n",
      "        [ 1.3001, -4.0434, -0.3712],\n",
      "        [-1.3802,  1.4527, -0.9003]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.sub(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4601,  1.7640,  1.0191, -2.3740,  0.3114])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9942])\n",
      "0.9942139387130737\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item()) # get value as number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors bridge to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy() # numpy view to a (reference)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # data copied (value transfer)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "a = a + 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in GPU\n",
    "\n",
    "This one need a GPU of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd of tensors\n",
    "\n",
    "Core to DNN: propagation of gradient to train the weights.\n",
    "Core to gradient: computing the gradient.\n",
    "Well, pytorch just got autograd which is as cool as it sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient information is everywhere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x1217be320>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x1217ae0b8>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradient\n",
    "\n",
    "Easy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't do it twice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-617965056ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/mktd-pytorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/mktd-pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1366.9066, -1143.9188,    -6.4782], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet architecture\n",
    "http://yann.lecun.com/exdb/lenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "leNet = Net()\n",
    "print(leNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(leNet.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.0896,  0.1447,  0.0419, -0.0402, -0.1495],\n",
      "          [-0.1326,  0.1096, -0.0191, -0.1165, -0.0272],\n",
      "          [-0.0674, -0.0582,  0.0528, -0.0213, -0.1811],\n",
      "          [-0.0393, -0.0355, -0.0069,  0.0284, -0.1924],\n",
      "          [-0.0632,  0.0014, -0.0214,  0.0847,  0.1070]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0615,  0.1394,  0.1102,  0.1709, -0.0525],\n",
      "          [ 0.1266, -0.0722, -0.1876,  0.1302, -0.1064],\n",
      "          [ 0.0700,  0.1996,  0.1887,  0.0772, -0.0034],\n",
      "          [-0.0962,  0.1499,  0.1804,  0.1565,  0.0830],\n",
      "          [-0.0007,  0.1336, -0.1253,  0.1186, -0.0370]]],\n",
      "\n",
      "\n",
      "        [[[-0.0220,  0.0131, -0.0113, -0.1854,  0.1309],\n",
      "          [ 0.1776,  0.0584, -0.0189,  0.1582, -0.0103],\n",
      "          [ 0.0184, -0.1426, -0.0666,  0.1983,  0.1384],\n",
      "          [ 0.1768, -0.0827, -0.1564,  0.1112,  0.0363],\n",
      "          [-0.0337,  0.0953,  0.1696,  0.0392, -0.0180]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1465, -0.1221,  0.0468,  0.0867,  0.1265],\n",
      "          [-0.1444, -0.1266,  0.1207,  0.1348, -0.0916],\n",
      "          [ 0.1161,  0.0037,  0.1631,  0.1399, -0.1778],\n",
      "          [ 0.0929,  0.1291,  0.1991, -0.1002, -0.0279],\n",
      "          [-0.0097,  0.1930,  0.0431,  0.1684,  0.1546]]],\n",
      "\n",
      "\n",
      "        [[[-0.1457,  0.0053, -0.1156,  0.1474, -0.1407],\n",
      "          [ 0.1508, -0.0531,  0.0751, -0.0415,  0.0604],\n",
      "          [ 0.1722,  0.1368, -0.0005, -0.0851, -0.1875],\n",
      "          [ 0.1247, -0.1875, -0.1491, -0.1579,  0.0258],\n",
      "          [-0.0182, -0.1054, -0.1509,  0.0567,  0.1688]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0078, -0.0398, -0.1449,  0.1402,  0.1827],\n",
      "          [-0.0256, -0.1907, -0.0123,  0.1292, -0.1877],\n",
      "          [-0.0754,  0.1931,  0.1229,  0.1306,  0.1752],\n",
      "          [ 0.0388, -0.1843, -0.0473,  0.0451,  0.1177],\n",
      "          [ 0.1273, -0.1303, -0.0440,  0.0204, -0.1990]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1686, -0.1373, -0.1123,  0.0356, -0.0533, -0.0551],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-4.9468e-02,  6.9362e-02,  4.0368e-02, -7.5569e-02,  6.0837e-02],\n",
      "          [ 2.0328e-02, -6.7429e-02,  6.0961e-02,  5.5924e-03, -6.6506e-02],\n",
      "          [ 7.5812e-02,  2.7310e-02, -7.2803e-02, -6.7115e-02, -8.0589e-02],\n",
      "          [ 4.3367e-02, -1.7896e-02,  5.2171e-02,  5.7344e-02,  4.3403e-02],\n",
      "          [ 1.9980e-02, -1.3815e-02, -4.2482e-02, -3.7224e-02, -7.4278e-02]],\n",
      "\n",
      "         [[-6.7933e-02, -6.7116e-02,  6.0794e-02,  4.9170e-02,  1.9868e-04],\n",
      "          [-2.1514e-02,  7.1201e-02, -5.3301e-02,  3.7543e-02,  8.1352e-02],\n",
      "          [-6.4829e-02, -4.3239e-02, -6.8732e-02,  6.1759e-02, -1.4752e-02],\n",
      "          [-2.4599e-02, -1.0528e-02,  4.1971e-02, -3.1534e-03, -4.2229e-02],\n",
      "          [ 2.6231e-02, -2.6921e-02, -2.6013e-02,  5.4460e-02,  1.2957e-02]],\n",
      "\n",
      "         [[ 5.0258e-02, -1.5699e-02,  1.7780e-02,  5.0357e-02,  1.6868e-02],\n",
      "          [ 7.5838e-02,  7.0884e-03,  2.0214e-02, -2.6903e-03, -2.4539e-02],\n",
      "          [-3.6491e-02, -8.0914e-02,  1.3448e-02, -3.6304e-02,  5.6819e-02],\n",
      "          [ 4.7315e-02, -7.9357e-02, -7.9073e-02,  3.6558e-02, -3.4247e-02],\n",
      "          [-4.9197e-02,  7.2343e-02,  5.2885e-02, -3.7272e-02,  7.6646e-02]],\n",
      "\n",
      "         [[-6.0790e-02,  7.7339e-02, -6.5612e-02, -2.6321e-02, -1.5940e-02],\n",
      "          [-6.5176e-02, -3.2491e-02, -1.1658e-02,  1.5267e-02, -3.4917e-02],\n",
      "          [-6.9218e-02,  5.6595e-03, -1.6589e-02,  5.6772e-02, -7.3101e-02],\n",
      "          [ 6.9322e-03, -4.7206e-02, -3.5594e-02, -8.0028e-02, -1.2061e-03],\n",
      "          [ 1.3138e-02,  2.6766e-02,  5.2076e-02, -1.7446e-02, -1.2883e-02]],\n",
      "\n",
      "         [[-5.0972e-02, -2.7875e-02, -5.2642e-02, -5.0592e-02, -5.2848e-02],\n",
      "          [-5.5389e-02,  2.8788e-02, -2.8013e-02,  1.4520e-02, -2.2264e-02],\n",
      "          [ 5.0933e-02, -1.5564e-02, -4.5939e-02,  4.6465e-02,  7.2651e-02],\n",
      "          [-1.4225e-02, -6.2291e-02,  7.2467e-02,  6.0274e-02,  1.6749e-02],\n",
      "          [-6.0298e-02,  1.4818e-02,  1.0128e-02, -6.8195e-02,  2.2826e-02]],\n",
      "\n",
      "         [[-2.2212e-02, -5.6875e-02,  1.2576e-02, -8.0597e-02,  2.7120e-03],\n",
      "          [ 7.2938e-02, -1.0881e-02, -1.3244e-02,  3.0987e-02, -7.3840e-03],\n",
      "          [-5.5078e-02, -6.6301e-03, -7.9222e-02,  4.1926e-02,  3.9110e-02],\n",
      "          [-7.5650e-02,  6.6963e-02, -1.5325e-02,  3.0590e-02,  4.6010e-02],\n",
      "          [-7.1941e-02,  4.1095e-02,  6.0651e-02, -6.6808e-02, -3.0712e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5699e-02, -7.8361e-02, -8.3145e-03,  2.1397e-02, -1.0205e-02],\n",
      "          [-4.3223e-03,  4.4349e-02, -1.0767e-02,  3.9843e-03, -7.1306e-03],\n",
      "          [ 4.2560e-02, -1.8369e-02,  4.8263e-02, -6.1486e-02, -1.9276e-02],\n",
      "          [ 3.9558e-02, -1.4274e-02,  7.3474e-02,  4.0192e-03, -7.5607e-02],\n",
      "          [-3.7069e-02, -5.4602e-02, -6.7310e-02,  1.9425e-02, -2.5262e-02]],\n",
      "\n",
      "         [[ 4.1727e-02, -1.8731e-02,  3.1838e-02, -5.0995e-02, -7.2040e-02],\n",
      "          [-5.9607e-02,  3.0012e-02, -5.6923e-02,  2.1962e-02, -7.9134e-02],\n",
      "          [ 7.3140e-02, -3.2878e-02, -1.1370e-02,  2.7150e-02, -6.6622e-02],\n",
      "          [ 5.5422e-02,  2.4067e-02, -2.7605e-03, -3.5286e-02, -1.9050e-02],\n",
      "          [-2.6649e-03, -4.3961e-02, -1.3020e-02,  7.6438e-02,  3.6804e-02]],\n",
      "\n",
      "         [[-1.2658e-02,  2.7396e-02, -1.9974e-03, -6.5222e-02, -7.9145e-02],\n",
      "          [ 5.4100e-02, -7.2970e-02, -5.2089e-02,  2.5649e-02, -5.8513e-02],\n",
      "          [-3.0661e-02, -6.6484e-02, -5.4441e-02,  2.7871e-02,  7.6657e-02],\n",
      "          [-6.7192e-02,  5.8298e-02, -2.4250e-02,  7.2179e-02,  6.5789e-02],\n",
      "          [ 6.3656e-02,  1.7006e-02, -5.7280e-02, -5.2060e-02, -7.0877e-02]],\n",
      "\n",
      "         [[ 3.3394e-02, -3.0509e-02, -9.4246e-03, -6.9849e-02,  5.6104e-02],\n",
      "          [-2.7293e-02, -3.6164e-02, -2.2790e-02, -7.9423e-02, -7.6071e-02],\n",
      "          [-5.2892e-05,  6.2105e-02,  2.8520e-02,  3.3463e-03,  2.8802e-02],\n",
      "          [ 6.4772e-03,  4.9690e-02, -7.5695e-02,  3.5658e-02, -3.8221e-02],\n",
      "          [ 1.7963e-02, -1.6071e-02,  3.0020e-02, -3.2417e-02, -5.8939e-02]],\n",
      "\n",
      "         [[ 2.9896e-02,  5.9935e-02, -6.3292e-02,  6.1658e-02,  4.3209e-02],\n",
      "          [-4.9094e-02,  7.3407e-03,  7.7381e-02, -5.9287e-02, -3.8203e-02],\n",
      "          [-5.0167e-02, -7.9622e-02, -1.7637e-02,  3.0852e-02,  1.1760e-02],\n",
      "          [ 6.3308e-02,  6.1598e-02, -2.3281e-02,  2.6876e-02,  3.1528e-02],\n",
      "          [-5.4514e-02,  5.1591e-02,  6.1914e-02,  2.8215e-02, -4.9241e-02]],\n",
      "\n",
      "         [[ 5.8197e-02,  4.4913e-02,  1.5010e-02,  6.0623e-02, -6.7904e-03],\n",
      "          [-3.9109e-02,  5.6230e-02,  4.2710e-02,  5.9055e-02,  3.6029e-02],\n",
      "          [-7.2894e-03, -6.2265e-02, -1.4624e-02, -4.0640e-02, -1.0774e-02],\n",
      "          [ 1.7392e-02, -6.6793e-02,  3.9721e-04, -3.2541e-02, -4.6019e-02],\n",
      "          [ 7.7267e-02,  8.1225e-02, -7.2054e-02, -4.6106e-02, -7.1176e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5273e-02,  4.4424e-02, -1.4408e-02, -3.6160e-02,  3.0137e-02],\n",
      "          [ 5.5033e-02,  2.3957e-02,  3.5924e-02,  4.4009e-02, -2.8148e-02],\n",
      "          [-7.2102e-02, -6.1474e-02, -6.6971e-02,  7.1362e-03,  5.0156e-02],\n",
      "          [ 4.8702e-02,  5.1264e-02,  4.4390e-02, -7.5913e-02, -5.1628e-02],\n",
      "          [-6.2703e-02,  5.9712e-03,  6.8760e-02,  1.9426e-02,  1.7457e-02]],\n",
      "\n",
      "         [[ 7.9849e-02,  2.8377e-02, -4.2643e-02,  5.7566e-02,  2.4785e-02],\n",
      "          [ 5.0514e-02,  4.1916e-02, -1.6529e-02, -6.6705e-02, -6.5585e-02],\n",
      "          [-3.9741e-02,  1.9216e-02, -3.2516e-02,  5.6275e-02,  3.6950e-02],\n",
      "          [ 6.7334e-03, -1.5226e-02,  1.1099e-02,  1.3023e-02, -4.4837e-02],\n",
      "          [ 4.9081e-02,  1.9347e-02,  1.2174e-02,  6.4635e-02, -7.0999e-02]],\n",
      "\n",
      "         [[-7.0836e-02, -1.8685e-02,  5.8828e-02,  1.0963e-02,  6.5149e-02],\n",
      "          [ 5.4318e-02,  6.2197e-02,  4.1396e-02, -1.2651e-02, -8.1270e-03],\n",
      "          [-5.4005e-02,  2.5157e-02,  1.0402e-02,  4.3971e-02, -4.7485e-02],\n",
      "          [ 6.1444e-02, -6.6549e-02, -6.3833e-02,  5.0689e-02,  3.6565e-02],\n",
      "          [ 1.4341e-02, -8.6415e-03, -7.3783e-02,  3.7747e-02,  2.4088e-02]],\n",
      "\n",
      "         [[ 6.6587e-02,  7.1086e-02, -6.8991e-03, -3.8865e-02,  1.8590e-02],\n",
      "          [-3.5896e-02,  9.5303e-03, -5.9279e-02,  4.7940e-02,  8.2151e-03],\n",
      "          [-2.4537e-02, -2.5604e-02,  1.8001e-02, -7.5524e-02, -2.4698e-02],\n",
      "          [-5.7027e-02, -4.7902e-02, -7.3133e-02,  1.0422e-02,  5.5792e-02],\n",
      "          [-3.5387e-02,  1.0703e-02,  7.3844e-02,  2.8158e-02, -5.5813e-02]],\n",
      "\n",
      "         [[-3.1418e-02, -2.8003e-02,  8.2052e-03,  5.6744e-02,  6.1484e-02],\n",
      "          [-4.8433e-02,  1.7530e-02,  1.1044e-02, -6.7571e-02, -2.3152e-02],\n",
      "          [ 7.1340e-02,  6.6782e-02,  3.1920e-02, -6.1395e-02,  7.5586e-02],\n",
      "          [-2.0937e-02,  7.0695e-02, -2.8331e-03, -5.9554e-02,  6.3346e-02],\n",
      "          [-7.9510e-02, -3.4756e-03,  1.9545e-02,  4.9249e-02, -4.6833e-02]],\n",
      "\n",
      "         [[ 4.1120e-02, -5.1362e-02,  8.9177e-03,  2.4787e-02,  7.6810e-02],\n",
      "          [-5.7922e-02,  4.1877e-02, -3.7802e-02,  5.2232e-02,  5.1706e-02],\n",
      "          [ 2.0899e-02,  8.8795e-03, -4.3548e-02,  6.7647e-02,  4.6566e-02],\n",
      "          [-7.1217e-02,  4.6131e-02, -2.1665e-02,  6.3911e-02,  7.7180e-02],\n",
      "          [ 1.5471e-02,  2.5106e-02,  7.9490e-02,  1.1750e-03, -8.0951e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.7271e-02,  1.9820e-02,  5.9593e-02,  5.4594e-02,  1.4688e-02],\n",
      "          [ 4.5521e-02, -7.3444e-02, -1.6976e-02,  6.2108e-02, -3.2156e-02],\n",
      "          [-6.7302e-02, -3.9182e-02, -1.9571e-02, -1.4263e-02, -5.7533e-02],\n",
      "          [-6.5504e-03,  6.3008e-02,  6.4994e-03,  3.7720e-02,  4.9985e-03],\n",
      "          [-4.4289e-02, -6.6024e-02, -6.2119e-02,  1.8642e-03, -3.4418e-02]],\n",
      "\n",
      "         [[ 7.9468e-02, -3.3479e-02, -2.4042e-02,  7.5312e-02, -4.0362e-02],\n",
      "          [ 5.2136e-03,  7.1460e-03, -9.9284e-03, -1.9264e-02, -4.6007e-02],\n",
      "          [ 2.5925e-02, -6.8924e-03,  2.2103e-02,  2.5026e-02, -4.5975e-02],\n",
      "          [ 5.9645e-02, -6.3734e-02,  5.1310e-02,  4.3376e-02, -6.9579e-02],\n",
      "          [-2.8226e-02,  2.4258e-02, -9.4148e-03, -5.3542e-02, -3.0006e-02]],\n",
      "\n",
      "         [[ 6.9117e-02, -3.4939e-02, -4.5075e-02,  2.0937e-02,  6.0317e-02],\n",
      "          [ 2.4789e-02,  3.4532e-02, -6.4660e-02, -6.9711e-02,  2.4943e-02],\n",
      "          [ 3.7955e-02,  4.6221e-02, -1.9811e-02, -3.3479e-03,  1.0174e-02],\n",
      "          [-1.8106e-02, -5.7209e-02, -5.1062e-02, -7.4133e-02,  2.2020e-02],\n",
      "          [ 1.2471e-02, -7.6390e-02, -1.6770e-02, -3.9630e-02,  1.5369e-02]],\n",
      "\n",
      "         [[-1.0495e-02, -4.8355e-02, -6.9701e-02, -1.1198e-03,  1.3453e-02],\n",
      "          [ 5.2420e-02, -4.4076e-02, -2.7273e-02,  5.1540e-02,  1.6244e-02],\n",
      "          [ 6.8112e-02, -3.5766e-02, -4.9981e-02, -2.5457e-02, -6.3799e-03],\n",
      "          [-4.8870e-02,  2.8798e-03, -6.5953e-02, -6.1626e-02, -6.8238e-02],\n",
      "          [ 1.5741e-02,  3.5872e-02,  8.1435e-02,  3.8660e-02,  7.6156e-02]],\n",
      "\n",
      "         [[-7.8994e-02,  1.4880e-02, -7.7680e-02,  5.8338e-02,  7.6812e-02],\n",
      "          [-6.1893e-02, -3.5617e-02,  2.5720e-02,  7.6231e-02,  5.2060e-02],\n",
      "          [-6.0164e-02, -3.1326e-03,  7.7868e-03, -2.9293e-02,  8.7624e-03],\n",
      "          [-2.1705e-03, -2.1009e-02, -2.1256e-02,  1.2923e-02, -5.8563e-02],\n",
      "          [ 1.2567e-02,  5.9049e-02,  3.5281e-02,  5.7570e-02, -1.8947e-02]],\n",
      "\n",
      "         [[ 4.3844e-02,  6.9050e-03,  5.0390e-02, -4.7901e-02, -6.1869e-02],\n",
      "          [-5.4444e-02,  1.5245e-02,  4.4313e-02,  5.4351e-02, -7.3169e-02],\n",
      "          [-7.6097e-02, -1.2976e-02, -2.2362e-02,  5.2725e-02,  2.4944e-02],\n",
      "          [ 3.1092e-02,  2.4271e-02, -5.7910e-02, -7.3723e-02,  5.0185e-02],\n",
      "          [-8.5498e-03, -7.5568e-03, -6.2868e-04,  5.8620e-02, -4.0056e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.9102e-02,  3.2231e-02,  6.1668e-02, -5.8508e-03,  2.1762e-02],\n",
      "          [ 4.3645e-02,  2.8315e-02, -2.6976e-02, -2.5055e-02,  5.0483e-02],\n",
      "          [-7.7776e-02,  5.9054e-03, -4.7399e-02, -1.6791e-02, -4.2103e-02],\n",
      "          [-1.9387e-03,  3.6958e-02, -3.1428e-02,  1.6125e-02, -4.9049e-02],\n",
      "          [ 7.3432e-02, -6.6419e-02,  1.2817e-02,  4.4567e-02, -6.4085e-02]],\n",
      "\n",
      "         [[ 6.5640e-02, -7.9614e-02, -2.1120e-02,  7.9385e-02,  7.0472e-02],\n",
      "          [ 6.2097e-02,  1.8802e-02,  3.9751e-03, -2.1490e-02,  7.6758e-03],\n",
      "          [ 7.4742e-02, -1.7374e-02,  2.5807e-02,  5.7083e-02,  1.4411e-02],\n",
      "          [ 5.4379e-02,  3.1062e-02, -1.8875e-02,  9.6846e-03,  1.1503e-02],\n",
      "          [ 6.4336e-02,  4.9855e-02,  2.8549e-02, -4.1793e-02, -4.8818e-02]],\n",
      "\n",
      "         [[-5.4872e-02,  2.8523e-02, -1.6761e-02,  2.0155e-02, -2.7851e-02],\n",
      "          [-5.1861e-02, -7.7332e-03, -5.7396e-02,  3.8793e-02, -2.3233e-02],\n",
      "          [ 4.4992e-02,  5.9837e-03, -2.1306e-02, -4.1353e-02,  6.9062e-02],\n",
      "          [-6.0871e-02,  7.9410e-02,  6.5012e-02, -9.2432e-04, -2.0688e-02],\n",
      "          [ 1.8937e-02, -5.1136e-02,  1.1733e-02, -3.4404e-03,  2.0509e-02]],\n",
      "\n",
      "         [[ 5.9868e-02, -3.8213e-02,  5.0486e-02, -6.5602e-02,  3.5647e-02],\n",
      "          [-9.7785e-03, -7.9088e-02,  3.7498e-02,  7.5326e-02, -3.0775e-02],\n",
      "          [ 7.2466e-02,  1.3212e-02, -1.0101e-03,  3.9250e-02,  8.1031e-02],\n",
      "          [-2.0467e-02,  7.7906e-02,  5.0210e-02, -9.8224e-03,  7.8924e-02],\n",
      "          [-6.1228e-02, -1.5342e-02, -6.2016e-02, -7.4542e-02, -7.0224e-02]],\n",
      "\n",
      "         [[-5.7816e-02, -8.0023e-02,  2.5245e-02,  4.0481e-02,  1.8759e-02],\n",
      "          [ 2.3613e-02, -4.9442e-02,  6.1985e-02,  1.1522e-02,  3.4984e-02],\n",
      "          [-1.7566e-02, -6.0975e-02,  3.8398e-02,  6.2686e-02, -2.3352e-02],\n",
      "          [-1.4976e-02,  1.3520e-02, -3.2613e-02, -7.2090e-02, -1.4572e-02],\n",
      "          [ 7.8340e-02, -3.7381e-02, -2.7867e-03, -5.4284e-02, -7.4233e-02]],\n",
      "\n",
      "         [[ 2.3814e-03,  6.7018e-02,  5.9598e-02,  1.3067e-03,  2.6985e-02],\n",
      "          [ 3.1937e-02,  3.1686e-02, -1.3815e-04, -5.3807e-03, -1.5060e-02],\n",
      "          [-7.7062e-02, -4.1609e-02,  1.6466e-02, -6.1952e-02,  4.3497e-02],\n",
      "          [-7.4974e-02,  5.8592e-02, -9.8122e-03,  8.1532e-02, -4.6995e-02],\n",
      "          [-4.7921e-02,  4.8056e-03, -4.8596e-02, -2.4770e-03, -6.9816e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6017e-02, -5.1772e-03, -4.7393e-02, -7.1814e-02, -1.6450e-02],\n",
      "          [-7.6355e-02,  4.9529e-02, -1.6185e-03,  5.3388e-02, -6.1849e-04],\n",
      "          [-1.2208e-03,  2.0935e-02, -3.7955e-02,  3.1736e-02,  4.1990e-02],\n",
      "          [ 2.1681e-02,  5.1026e-02, -8.1086e-02, -1.2818e-02,  6.9482e-02],\n",
      "          [-4.6900e-02,  4.9805e-02, -2.4162e-02,  1.2444e-02,  4.9002e-02]],\n",
      "\n",
      "         [[-1.5471e-02,  3.5923e-03, -5.9809e-02, -2.3309e-02,  1.3895e-03],\n",
      "          [ 2.9626e-02,  7.8587e-02, -4.9441e-02,  3.6241e-02,  5.9855e-02],\n",
      "          [ 2.2973e-02, -6.7351e-02, -3.6761e-02, -1.4601e-02,  9.0872e-04],\n",
      "          [ 4.0351e-02, -1.9258e-02, -7.6330e-02, -2.6417e-02, -1.0218e-02],\n",
      "          [ 4.6347e-02,  9.8436e-03, -2.8659e-02, -4.7924e-03,  1.1386e-02]],\n",
      "\n",
      "         [[-2.8266e-02, -2.6807e-02,  3.0603e-02,  5.8350e-02,  2.7426e-02],\n",
      "          [ 3.3014e-02,  5.7906e-02, -3.7715e-02, -6.8343e-02,  1.2786e-02],\n",
      "          [ 7.6654e-02,  4.0432e-02,  5.8678e-02,  2.5729e-02,  4.0724e-02],\n",
      "          [-2.1100e-02, -2.7900e-02,  5.0637e-02,  5.9824e-02, -7.5410e-02],\n",
      "          [ 1.8434e-03,  4.8774e-02, -5.2843e-02, -7.9542e-02, -3.0370e-02]],\n",
      "\n",
      "         [[ 6.6231e-02,  3.1477e-02,  5.3075e-02, -7.0226e-02, -8.1701e-03],\n",
      "          [-8.1382e-02, -7.6396e-03, -7.3261e-02,  3.4761e-02,  6.0476e-04],\n",
      "          [-1.4166e-02,  2.0445e-02,  5.7287e-02, -7.4862e-02,  7.2911e-02],\n",
      "          [-1.0003e-02,  4.9541e-02,  6.6758e-02,  4.8897e-02, -5.6360e-02],\n",
      "          [-1.8966e-02, -3.1044e-02, -2.6570e-03, -6.0104e-02, -8.0858e-02]],\n",
      "\n",
      "         [[-4.5432e-02, -6.2204e-02, -1.9855e-02, -5.6793e-02, -1.5868e-02],\n",
      "          [-8.8271e-03,  3.9385e-02,  5.7944e-02, -5.3699e-02,  7.5559e-02],\n",
      "          [-6.4493e-02,  4.9103e-04,  3.5874e-02, -2.1307e-02,  5.0964e-02],\n",
      "          [ 5.9535e-02, -2.6942e-02,  5.0337e-02,  4.0600e-02,  4.4749e-02],\n",
      "          [-5.2185e-02,  4.1060e-02,  5.1463e-02, -4.9752e-02, -7.7333e-02]],\n",
      "\n",
      "         [[ 2.1836e-02, -4.5512e-02, -7.3081e-02,  6.9537e-02, -3.2947e-04],\n",
      "          [-5.3309e-02,  6.4949e-02,  4.5287e-02, -2.0343e-02,  4.6005e-02],\n",
      "          [-4.9311e-02,  5.0195e-02, -5.6863e-03,  8.1567e-02, -1.4959e-02],\n",
      "          [ 4.5009e-02, -3.6674e-03,  5.9090e-02, -5.2756e-02, -5.4348e-02],\n",
      "          [-6.3627e-02, -3.2263e-02, -6.5513e-02,  3.9400e-03, -5.3753e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0233, -0.0147,  0.0469, -0.0257,  0.0237, -0.0440, -0.0008, -0.0081,\n",
      "         0.0261,  0.0494,  0.0292, -0.0378,  0.0139, -0.0318, -0.0521, -0.0511],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0091, -0.0307,  0.0418,  ..., -0.0451,  0.0458, -0.0353],\n",
      "        [ 0.0463,  0.0456,  0.0408,  ..., -0.0132, -0.0430,  0.0365],\n",
      "        [ 0.0066,  0.0060, -0.0165,  ..., -0.0385,  0.0347,  0.0136],\n",
      "        ...,\n",
      "        [ 0.0316, -0.0203,  0.0201,  ..., -0.0466,  0.0075, -0.0451],\n",
      "        [-0.0295, -0.0119,  0.0134,  ..., -0.0187, -0.0316, -0.0052],\n",
      "        [-0.0244, -0.0123,  0.0041,  ...,  0.0481, -0.0132,  0.0201]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0058, -0.0305,  0.0224,  0.0301,  0.0300,  0.0259, -0.0454, -0.0342,\n",
      "        -0.0352, -0.0459,  0.0394,  0.0203,  0.0016, -0.0097, -0.0203, -0.0253,\n",
      "         0.0401, -0.0224, -0.0280,  0.0339, -0.0058,  0.0403,  0.0106,  0.0233,\n",
      "         0.0345,  0.0046, -0.0443,  0.0114,  0.0355,  0.0046, -0.0367,  0.0068,\n",
      "        -0.0003,  0.0437,  0.0489,  0.0013, -0.0182, -0.0023, -0.0365,  0.0220,\n",
      "        -0.0388, -0.0363,  0.0336,  0.0228, -0.0186, -0.0447, -0.0208,  0.0226,\n",
      "        -0.0444,  0.0431, -0.0237, -0.0404, -0.0331, -0.0177,  0.0140, -0.0346,\n",
      "         0.0007, -0.0214,  0.0226, -0.0238, -0.0380,  0.0134,  0.0426, -0.0045,\n",
      "        -0.0429, -0.0058, -0.0341,  0.0284, -0.0366,  0.0291, -0.0327, -0.0037,\n",
      "         0.0038, -0.0352,  0.0046,  0.0156,  0.0041,  0.0407,  0.0158, -0.0429,\n",
      "        -0.0294,  0.0290,  0.0052, -0.0092,  0.0279, -0.0247,  0.0422,  0.0386,\n",
      "        -0.0406, -0.0152, -0.0186, -0.0014, -0.0214, -0.0227,  0.0064, -0.0136,\n",
      "        -0.0320,  0.0050,  0.0465,  0.0055, -0.0378, -0.0148, -0.0223, -0.0263,\n",
      "         0.0071, -0.0210, -0.0273, -0.0116,  0.0370, -0.0393,  0.0018,  0.0260,\n",
      "         0.0011,  0.0047, -0.0412, -0.0203,  0.0455, -0.0397, -0.0305, -0.0135],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0834, -0.0327,  0.0083,  ...,  0.0792, -0.0246, -0.0848],\n",
      "        [ 0.0638, -0.0054,  0.0399,  ...,  0.0776, -0.0746, -0.0382],\n",
      "        [ 0.0143, -0.0768, -0.0733,  ..., -0.0356,  0.0033, -0.0440],\n",
      "        ...,\n",
      "        [ 0.0007, -0.0131,  0.0027,  ...,  0.0901,  0.0763, -0.0230],\n",
      "        [ 0.0781,  0.0701,  0.0432,  ..., -0.0263,  0.0474,  0.0453],\n",
      "        [ 0.0121, -0.0626, -0.0700,  ...,  0.0008, -0.0383,  0.0631]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0460, -0.0568, -0.0856, -0.0818, -0.0750, -0.0493, -0.0807,  0.0051,\n",
      "        -0.0637,  0.0152,  0.0316,  0.0419,  0.0257, -0.0612,  0.0317, -0.0862,\n",
      "        -0.0641, -0.0126, -0.0036,  0.0730,  0.0536, -0.0396, -0.0757, -0.0687,\n",
      "        -0.0361,  0.0634,  0.0660, -0.0449, -0.0800,  0.0071,  0.0301,  0.0239,\n",
      "         0.0127,  0.0454, -0.0332,  0.0506, -0.0251,  0.0507,  0.0429, -0.0430,\n",
      "        -0.0667, -0.0038, -0.0118, -0.0277,  0.0412,  0.0021,  0.0692, -0.0585,\n",
      "         0.0796, -0.0208, -0.0654, -0.0704,  0.0174, -0.0792, -0.0377,  0.0557,\n",
      "         0.0742,  0.0427,  0.0188,  0.0367, -0.0564, -0.0011, -0.0347, -0.0104,\n",
      "        -0.0378, -0.0385, -0.0528, -0.0447, -0.0784, -0.0215, -0.0697,  0.0454,\n",
      "        -0.0801, -0.0757, -0.0743,  0.0452,  0.0558,  0.0206,  0.0362, -0.0861,\n",
      "        -0.0386, -0.0729, -0.0191,  0.0779], requires_grad=True), Parameter containing:\n",
      "tensor([[ 3.7839e-02, -4.6202e-02, -6.5405e-02, -1.4470e-02, -6.9074e-02,\n",
      "          3.2806e-02, -3.0375e-02, -9.8715e-02,  2.5094e-02,  9.8918e-02,\n",
      "         -1.0450e-01,  6.3116e-02,  6.8949e-02, -7.2589e-02, -3.6864e-02,\n",
      "         -5.6780e-02, -6.9132e-02,  8.1015e-02, -6.8092e-02,  3.2779e-02,\n",
      "         -7.6002e-02, -2.5042e-02, -7.8599e-02,  4.3463e-02, -7.8788e-02,\n",
      "         -3.6890e-02, -5.4066e-02,  7.1001e-02, -7.1433e-02, -7.9185e-02,\n",
      "          1.7005e-02, -6.9558e-02,  4.5334e-02, -9.9916e-02,  4.5119e-03,\n",
      "         -7.0876e-02, -9.2456e-03,  7.7895e-04, -9.3776e-02, -4.2246e-02,\n",
      "         -8.2468e-02,  1.0671e-01,  4.0805e-02, -9.5240e-02, -3.8863e-02,\n",
      "         -1.3555e-02, -8.9002e-02,  6.3605e-02,  5.1743e-02, -6.7882e-02,\n",
      "         -5.0006e-02, -2.7585e-02, -3.5646e-02,  1.0288e-01, -6.3716e-03,\n",
      "         -1.3527e-02, -7.8084e-02, -5.0438e-02,  6.8414e-02, -2.2216e-02,\n",
      "          6.6988e-02, -6.6922e-02, -7.1596e-02, -7.5915e-02, -9.5550e-02,\n",
      "         -9.2848e-02,  6.6416e-02,  4.7647e-02, -4.0943e-02,  1.0539e-01,\n",
      "         -5.7542e-02, -1.0784e-01,  8.2299e-03, -4.1283e-02, -7.2077e-02,\n",
      "          3.2605e-02,  8.8722e-02, -4.0702e-02,  3.2817e-02, -3.1140e-02,\n",
      "          6.7632e-02,  8.9011e-02, -5.8416e-02,  9.2504e-02],\n",
      "        [-9.9602e-02, -5.2024e-02,  2.8777e-02,  6.8932e-02,  4.4745e-02,\n",
      "         -6.0875e-02,  2.8206e-02, -2.4754e-02,  3.2311e-02,  7.7729e-02,\n",
      "          5.0353e-02, -1.8542e-03, -6.0359e-02,  1.6994e-02,  6.7304e-02,\n",
      "          8.7832e-02, -5.2324e-02, -7.0758e-02, -4.1975e-02,  6.3812e-02,\n",
      "         -7.7264e-02, -1.0000e-01,  8.0280e-02, -7.7618e-02,  1.8178e-02,\n",
      "         -1.0476e-01, -6.5239e-03,  8.0728e-02,  3.1396e-02,  1.0218e-01,\n",
      "          4.2640e-02,  1.0035e-01,  6.0496e-02, -2.2816e-02, -6.5527e-02,\n",
      "         -9.2718e-02,  7.6448e-02, -7.2669e-02,  9.4154e-02,  9.6571e-04,\n",
      "          3.9427e-02, -4.6352e-02,  1.3504e-02,  5.7495e-02,  5.4083e-02,\n",
      "          2.6805e-02, -7.1738e-02, -1.0504e-01, -9.5858e-03,  4.3445e-02,\n",
      "          5.1887e-02,  1.4867e-02, -8.4209e-02,  2.0082e-02,  4.0599e-02,\n",
      "          9.1530e-02,  7.0774e-02, -6.0002e-03, -6.9452e-02, -2.7597e-02,\n",
      "         -9.2029e-03, -6.5343e-02,  3.4006e-02, -6.9803e-02,  7.4724e-02,\n",
      "          9.1811e-04, -5.4293e-02,  5.4359e-02,  1.8679e-02,  1.0489e-01,\n",
      "         -1.0869e-01,  4.5741e-02, -5.1023e-03,  9.2456e-02,  1.0962e-03,\n",
      "          7.9450e-02,  5.1891e-02, -2.1582e-02,  1.0527e-02, -1.2113e-02,\n",
      "         -1.0647e-01,  5.1417e-02, -3.2694e-02, -4.6493e-03],\n",
      "        [ 1.0429e-01,  5.4189e-02, -1.3965e-02, -8.1985e-02,  1.0772e-01,\n",
      "          3.7240e-02,  7.1787e-03, -1.0023e-01,  1.4299e-02,  1.0418e-01,\n",
      "         -1.7234e-04, -5.5447e-02, -1.0497e-02,  3.4600e-02, -1.0715e-01,\n",
      "          8.7350e-02, -9.8385e-02,  4.1296e-02, -7.5736e-02, -4.3969e-02,\n",
      "         -8.9973e-02, -7.7346e-02,  6.6506e-02, -5.6883e-03, -7.8214e-02,\n",
      "         -1.0698e-01,  1.0866e-01, -8.4499e-02, -8.8214e-02,  3.5481e-02,\n",
      "         -4.6184e-02, -1.0557e-01, -4.3071e-02, -5.3205e-02, -9.8069e-02,\n",
      "          6.7712e-02, -6.8165e-02,  7.2153e-02,  7.3728e-02, -2.5007e-02,\n",
      "          1.0199e-01, -1.0777e-01,  7.0933e-02, -4.7302e-02, -3.9255e-03,\n",
      "          7.4509e-02,  7.9222e-02,  3.9821e-02, -1.7269e-02, -4.9937e-03,\n",
      "         -5.6489e-02, -4.4379e-02, -8.5085e-02,  6.2868e-02, -5.7414e-02,\n",
      "          7.4219e-02, -3.3677e-03, -4.5735e-02,  4.2314e-02, -1.0743e-01,\n",
      "         -5.9593e-02, -9.7370e-02,  1.5481e-02,  3.4342e-02,  9.7172e-02,\n",
      "          5.8222e-02, -3.1162e-02, -7.0018e-02,  1.3140e-02, -3.4682e-02,\n",
      "         -6.1899e-02,  5.0883e-02, -8.4934e-02,  4.2959e-02,  5.7437e-02,\n",
      "          8.7954e-02,  7.3883e-02,  9.3412e-02,  6.4336e-02, -9.0660e-02,\n",
      "         -2.3071e-02,  2.8685e-02,  1.0580e-01, -9.3589e-02],\n",
      "        [ 5.0572e-02, -7.7528e-02, -6.8215e-03,  1.9380e-02, -4.3694e-02,\n",
      "         -1.0234e-01,  5.8799e-02,  2.3733e-02, -7.4801e-02,  7.1348e-03,\n",
      "         -6.4391e-02, -5.7064e-02,  8.8744e-02,  8.6055e-02,  1.0355e-01,\n",
      "          9.9858e-02,  1.5072e-02, -5.1801e-02, -6.9965e-02, -7.4739e-02,\n",
      "          3.2510e-03, -1.4964e-03, -7.2180e-03,  9.9153e-02,  1.5542e-05,\n",
      "         -2.0045e-02,  1.0156e-01,  2.6791e-02, -6.4340e-02, -9.1049e-02,\n",
      "         -5.4024e-02, -1.0862e-01,  2.6833e-02, -1.3806e-02, -1.5982e-03,\n",
      "         -7.4224e-02,  7.2919e-02,  1.0053e-01,  3.7941e-02,  3.9323e-02,\n",
      "          7.4745e-02,  9.4856e-02, -4.4249e-02, -5.4612e-02,  3.3498e-02,\n",
      "          3.2873e-02,  2.0601e-02, -1.0324e-01,  1.0352e-01,  3.2057e-02,\n",
      "          8.9952e-02,  5.7516e-02,  1.0374e-01, -1.9988e-03,  5.4597e-02,\n",
      "          1.9133e-02,  9.2750e-02, -9.5101e-02,  3.6690e-02,  3.5533e-02,\n",
      "         -4.2441e-02, -6.3470e-02, -7.6695e-02, -2.5926e-02, -8.7900e-02,\n",
      "         -5.6339e-02, -2.5881e-02,  9.5878e-02,  7.4691e-02, -2.1955e-02,\n",
      "          8.7918e-02, -9.1999e-02, -6.7848e-02,  1.0414e-01, -4.6916e-02,\n",
      "         -2.4051e-03,  7.5527e-02,  2.1520e-02, -9.0252e-02,  7.1758e-02,\n",
      "          2.3489e-02,  4.5689e-02, -2.4515e-02,  1.0638e-01],\n",
      "        [-7.7652e-02,  9.4825e-02, -2.9666e-02,  8.8315e-02, -6.5803e-02,\n",
      "         -6.5767e-02,  3.0935e-02,  9.8976e-02, -3.0002e-02,  9.9412e-02,\n",
      "         -8.5494e-02,  5.9482e-02, -9.0227e-02,  5.1285e-02, -7.8866e-02,\n",
      "          2.2816e-02,  7.7025e-03, -8.3438e-02, -9.0661e-02, -7.9952e-02,\n",
      "         -4.1356e-02,  1.0108e-01, -4.6597e-02, -9.2816e-02,  1.3408e-02,\n",
      "          5.0730e-03,  1.0669e-01,  2.3226e-02,  9.5851e-02, -8.8415e-02,\n",
      "          9.0262e-02,  1.4615e-02, -2.7677e-02,  4.6413e-02, -9.2167e-02,\n",
      "         -4.7217e-02, -5.2175e-02, -8.0568e-02, -7.4325e-02,  4.5505e-02,\n",
      "         -9.0546e-03,  7.7974e-02,  3.7397e-02,  5.0524e-02, -3.4729e-02,\n",
      "         -1.0954e-02,  3.2922e-02, -6.9102e-02,  2.8469e-02,  3.1775e-02,\n",
      "          3.3364e-02, -3.3838e-02, -2.6993e-02, -9.6755e-02, -3.3685e-02,\n",
      "          6.2799e-02,  1.9853e-02, -4.7990e-02, -8.7267e-02,  5.2199e-02,\n",
      "         -2.3654e-02, -7.3882e-02,  8.4759e-02,  2.9494e-02, -7.8564e-02,\n",
      "         -2.3016e-02,  6.0885e-02, -5.0142e-02, -6.8099e-03,  6.3742e-02,\n",
      "         -3.8075e-02,  1.6887e-02,  4.6968e-02, -3.5401e-02,  1.0504e-01,\n",
      "         -8.5461e-02, -5.5986e-02,  1.2562e-02, -4.9021e-02,  8.0418e-02,\n",
      "         -6.3502e-02,  4.6522e-02,  5.3921e-02,  6.3037e-02],\n",
      "        [-6.2643e-02,  7.8144e-02, -1.6558e-02, -8.4691e-03,  7.4491e-02,\n",
      "         -1.0744e-01,  1.0830e-01, -1.0909e-01,  6.7816e-02, -9.4986e-02,\n",
      "         -7.8256e-02, -7.4878e-02,  3.2280e-02, -1.1959e-02,  1.3766e-02,\n",
      "          1.0725e-01,  3.5121e-02, -4.8486e-02,  2.9151e-02, -1.4685e-03,\n",
      "         -7.8370e-02, -5.4580e-02,  1.0288e-01,  7.1115e-02, -8.0428e-03,\n",
      "          1.3092e-02,  2.3687e-02, -1.8541e-02,  6.3858e-02, -6.7890e-02,\n",
      "          6.0297e-02,  4.6718e-02, -7.6763e-02,  9.6767e-02, -8.8784e-02,\n",
      "         -6.0957e-02, -7.2302e-02,  8.3473e-02, -1.2008e-02,  2.9556e-02,\n",
      "         -1.0284e-01,  1.0801e-01,  7.6066e-02, -8.9290e-02, -1.4337e-02,\n",
      "         -5.8911e-02, -9.6411e-04,  1.0128e-02,  8.2936e-02, -8.8914e-02,\n",
      "          1.0687e-01, -3.9741e-02, -9.5475e-02, -2.7173e-02, -1.0433e-01,\n",
      "          9.3060e-02, -3.9687e-02,  6.0967e-02,  8.8958e-02,  9.0972e-02,\n",
      "         -1.5321e-02, -6.0760e-02, -6.7295e-02, -3.2297e-02, -9.5114e-02,\n",
      "         -7.1179e-02,  4.7827e-02,  1.1757e-02, -1.0457e-01,  2.8181e-02,\n",
      "          5.4923e-02,  2.6029e-02,  8.6698e-02,  7.7426e-04, -4.5980e-02,\n",
      "         -1.0062e-01, -1.1505e-02,  8.3552e-02, -3.2091e-02, -6.7040e-02,\n",
      "         -8.7338e-02,  1.0631e-01, -7.5968e-02, -6.2255e-02],\n",
      "        [-2.4997e-02, -6.1437e-02,  4.2412e-02,  6.7896e-02, -6.6820e-02,\n",
      "          2.6791e-02,  2.9560e-02, -7.0949e-02,  2.1569e-02, -5.7607e-02,\n",
      "          6.6274e-02, -3.5310e-02,  3.3300e-02,  4.2308e-02, -1.0873e-01,\n",
      "          5.1049e-02, -1.9302e-02, -5.7836e-03,  4.7333e-02,  1.0777e-01,\n",
      "          1.7271e-02, -1.0307e-01,  1.0582e-01, -8.0425e-02,  8.3049e-02,\n",
      "          1.0899e-01,  8.1385e-02,  1.2387e-02, -1.1468e-02, -4.9095e-03,\n",
      "         -4.8531e-03, -3.8805e-02, -9.3978e-02, -5.9859e-02,  1.2322e-02,\n",
      "          4.3519e-02,  9.6321e-02,  2.3514e-05, -3.6705e-02, -7.4127e-02,\n",
      "          7.2091e-02,  4.1383e-03,  8.7864e-02, -4.1404e-02, -7.7743e-02,\n",
      "         -8.3298e-03,  1.7963e-02, -3.7290e-02,  7.2665e-02,  5.4556e-02,\n",
      "          2.6155e-02, -8.3200e-02,  7.4663e-02,  7.7223e-02,  4.8905e-02,\n",
      "          1.0267e-01,  8.7316e-02,  8.4331e-02, -6.3325e-02, -7.7920e-02,\n",
      "         -8.8476e-02,  9.0298e-02,  9.3183e-02,  7.0316e-02,  7.7311e-02,\n",
      "         -1.0043e-01,  7.6991e-02,  2.7505e-04,  5.7174e-02,  1.0866e-01,\n",
      "         -3.2695e-02,  2.3898e-02,  3.6110e-03,  9.3765e-02,  2.7006e-02,\n",
      "          3.5861e-02, -3.5979e-02, -6.9888e-02,  2.7921e-02, -1.0447e-01,\n",
      "          1.0305e-01,  4.5267e-02, -5.9840e-02, -4.4513e-02],\n",
      "        [-6.8416e-02, -6.9072e-02,  2.6275e-02,  3.4051e-04, -7.5300e-02,\n",
      "          8.9122e-02,  7.5127e-02, -9.2072e-02, -8.4123e-02,  3.1551e-02,\n",
      "         -9.4761e-02,  7.4261e-02,  5.2772e-02,  1.6741e-02, -5.7687e-02,\n",
      "         -4.4306e-03,  5.2200e-02, -7.5133e-02, -1.0035e-01, -3.6740e-02,\n",
      "          3.4170e-03,  1.0123e-01, -4.9798e-02, -5.6625e-02, -4.8309e-02,\n",
      "         -8.7142e-02,  4.8766e-02, -2.0091e-02,  3.3300e-02,  6.5588e-02,\n",
      "          2.5852e-02,  2.6383e-02,  2.8463e-02,  3.0838e-02, -8.2777e-02,\n",
      "         -7.2429e-02,  6.8495e-02, -5.0089e-03, -8.6137e-03,  9.0595e-02,\n",
      "          5.8387e-02,  4.2705e-02, -9.3124e-02,  3.5075e-02, -3.4449e-02,\n",
      "         -2.3093e-02,  8.8266e-02, -2.3961e-02,  9.6805e-02, -6.4571e-02,\n",
      "         -5.2511e-02, -8.9511e-02, -5.7905e-02, -2.4006e-02,  5.3390e-02,\n",
      "         -4.3429e-03, -3.7548e-02, -9.2171e-02, -5.5549e-02,  1.0893e-01,\n",
      "         -6.0159e-02,  8.0231e-02, -7.3521e-02,  9.6166e-02, -5.8384e-02,\n",
      "         -9.4165e-02, -1.0391e-01, -4.4838e-02,  9.0684e-02,  3.6174e-02,\n",
      "         -1.0630e-01,  6.2147e-02,  4.7453e-02, -4.5874e-02,  1.1902e-02,\n",
      "          5.4307e-02,  8.3210e-02,  3.2311e-02, -8.8831e-02, -9.3429e-02,\n",
      "          6.3041e-02,  6.6365e-03,  2.4027e-02, -1.1484e-02],\n",
      "        [-7.6437e-02,  5.9447e-02,  1.0419e-01, -1.0710e-02, -9.1721e-03,\n",
      "          2.5709e-02,  4.4220e-02, -3.9489e-02, -7.0263e-02, -3.1214e-03,\n",
      "          1.7722e-02,  5.9741e-02, -5.1309e-02, -1.0346e-01,  1.1585e-02,\n",
      "         -2.1455e-02,  3.2936e-02, -1.3514e-02,  7.3624e-02, -8.8282e-02,\n",
      "          6.9697e-02, -8.7282e-02, -8.1729e-03,  4.1143e-02, -6.9311e-02,\n",
      "          5.0618e-02, -2.2033e-02,  9.9329e-02, -3.9581e-02,  1.0714e-01,\n",
      "          1.6822e-02,  9.8475e-02,  5.1840e-03,  4.2185e-02, -4.6298e-02,\n",
      "         -8.2459e-02, -8.3390e-02, -5.0153e-02, -8.5870e-02,  1.0075e-01,\n",
      "          7.0700e-02, -4.5762e-02, -1.7388e-02,  6.8049e-02,  1.0847e-01,\n",
      "         -8.0676e-02,  6.3526e-02,  3.2792e-02,  4.9938e-02, -2.7760e-02,\n",
      "          7.9531e-02, -4.1091e-02, -1.4712e-02, -1.0150e-01, -2.2500e-02,\n",
      "         -1.7445e-02, -5.5241e-02,  2.2144e-02,  2.5853e-02,  8.4746e-02,\n",
      "          2.8105e-02,  3.1998e-02,  7.5793e-02, -5.5536e-02,  6.4121e-02,\n",
      "          2.4135e-02,  1.0328e-01, -2.9958e-02, -7.6883e-02, -5.8016e-02,\n",
      "          8.9812e-02, -5.9180e-02, -3.1004e-02,  1.8652e-02, -5.6444e-02,\n",
      "          3.9473e-02,  7.5946e-02, -4.5530e-02,  4.4661e-02,  7.9557e-02,\n",
      "         -7.8238e-02, -8.1589e-02,  9.6409e-02, -2.3624e-02],\n",
      "        [-1.0358e-01, -1.0030e-01, -8.3489e-02,  3.1241e-02, -7.8344e-02,\n",
      "         -4.3011e-03, -6.0825e-02, -4.0361e-02,  2.7013e-02, -9.1807e-02,\n",
      "          7.3151e-03, -4.0122e-02, -1.8500e-02,  9.7202e-02,  9.5217e-02,\n",
      "          9.7749e-02, -1.0238e-01,  7.7430e-02, -7.5458e-02,  1.0314e-01,\n",
      "         -7.0201e-03,  2.8429e-02, -2.1391e-02,  2.3605e-02, -1.4579e-02,\n",
      "         -8.7578e-02,  1.0868e-02,  5.7553e-02,  5.9181e-02,  7.1976e-02,\n",
      "          1.5781e-02, -9.5848e-03,  7.1665e-02,  9.5050e-02,  5.6244e-02,\n",
      "         -4.1209e-03, -9.3912e-02,  3.4173e-02,  8.2331e-03, -9.9287e-03,\n",
      "          7.2467e-02, -2.9638e-02, -1.6356e-02,  3.7462e-02,  3.7242e-02,\n",
      "         -2.5681e-02,  6.9574e-02,  9.0110e-02,  7.3460e-02, -7.2806e-02,\n",
      "          3.9057e-02, -1.0034e-01, -2.2450e-02, -2.0271e-02,  9.3763e-02,\n",
      "          5.6694e-02,  4.7787e-02, -1.0354e-01,  1.7519e-02, -1.4880e-02,\n",
      "         -3.1658e-02, -5.2222e-02,  6.6994e-02,  1.2722e-03, -8.2207e-02,\n",
      "         -8.0586e-02,  2.9577e-02,  1.2110e-02, -5.1475e-02, -6.4214e-02,\n",
      "         -7.7460e-02, -4.5117e-02, -4.1484e-02,  8.5193e-02,  5.7206e-02,\n",
      "         -3.1586e-02,  1.5880e-02, -5.0466e-02, -1.7547e-02, -2.3459e-02,\n",
      "         -7.0896e-02,  3.3452e-03,  4.5696e-02,  8.0088e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1018,  0.0952, -0.0091,  0.1078,  0.0724, -0.0948,  0.0882,  0.0008,\n",
      "        -0.0686,  0.0714], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0497,  0.1080, -0.0544,  0.1040,  0.0961, -0.0908,  0.1231, -0.0039,\n",
      "         -0.0105,  0.0756]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = leNet(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(leNet.state_dict(), './leNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherNet = Net()\n",
    "anotherNet.load_state_dict(torch.load('./leNet.h5'))\n",
    "anotherNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0696, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32) # random input\n",
    "output = leNet(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x1217cebe0>\n",
      "<AddmmBackward object at 0x1217cee80>\n",
      "<AccumulateGrad object at 0x1217cebe0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0013, -0.0150, -0.0164,  0.0053, -0.0117, -0.0126])\n"
     ]
    }
   ],
   "source": [
    "leNet.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(leNet.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(leNet.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "# optimizer = optim.SGD(leNet.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(leNet.parameters(), lr=2e-3)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = leNet(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/loading during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "stamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%dT%H.%M.%S')\n",
    "torch.save({\n",
    "            'epoch': 1,\n",
    "            'model_state_dict': leNet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'checkpoint-{}.last'.format(stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(leNet.parameters(), lr=0.01)\n",
    "\n",
    "checkpoint = torch.load('checkpoint-{}.last'.format(stamp))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset\n",
    "\n",
    "Remember lesson 1?\n",
    "\n",
    "#### Loading MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_path = './data'\n",
    "\n",
    "#trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=data_path, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=data_path, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 32, 32])\n",
      "8\n",
      "<class 'torch.Tensor'> torch.Size([32, 1, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "sample = train_set[random.randint(1,len(train_set))]\n",
    "print(type(sample[0]), sample[0].shape)\n",
    "print(sample[1].item())\n",
    "\n",
    "tensor_image = sample[0].view(sample[0].shape[2], sample[0].shape[0], sample[0].shape[1])\n",
    "print(type(tensor_image), tensor_image.shape)\n",
    "\n",
    "tensor_image = torch.squeeze(tensor_image)\n",
    "\n",
    "plt.imshow(tensor_image, cmap='gray', interpolation='none')\n",
    "plt.title(\"Ground Truth: {}\".format(sample[1].item()))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mktd-pytorch",
   "language": "python",
   "name": "mktd-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
