{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices\n",
    "\n",
    "With each exercice will teach you one aspect of deep learning.\n",
    "The process of machine learning can be decompose in 7 steps :\n",
    "\n",
    "0. Data acquisition\n",
    "1. Data preparation\n",
    "2. Model definition\n",
    "3. Model training\n",
    "4. Model evaluation\n",
    "5. Hyperparameter tuning\n",
    "6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Model definition\n",
    "\n",
    "from https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "#### Initialization of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 4.6566e-10, 0.0000e+00],\n",
      "        [4.6566e-10, 3.1171e-19, 1.4013e-45],\n",
      "        [6.4696e-32, 1.4013e-45, 3.3538e-19],\n",
      "        [1.4013e-45, 3.1312e-19, 1.4013e-45],\n",
      "        [7.0589e-32, 1.4013e-45, 7.0955e-32]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4062, 0.7072, 0.9770],\n",
      "        [0.1909, 0.7009, 0.1559],\n",
      "        [0.8525, 0.7729, 0.3017],\n",
      "        [0.1037, 0.5744, 0.3012],\n",
      "        [0.0555, 0.4901, 0.0966]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.3147,  0.1742,  1.8138],\n",
      "        [-1.6407, -0.9755,  0.1839],\n",
      "        [-0.2354, -0.6075,  1.1882],\n",
      "        [ 0.0204,  1.2262,  0.1433],\n",
      "        [-0.2412,  1.6028, -0.7083]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2026, -0.1971,  2.1713],\n",
      "        [-1.0568, -2.5296,  0.5134],\n",
      "        [ 0.1837, -1.6991,  1.9190],\n",
      "        [ 1.2808,  1.8063, -1.2301],\n",
      "        [-0.4623, -0.0785, -2.1711]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn_like(x, dtype=torch.float) \n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5732,  0.5455,  1.4563],\n",
      "        [-2.2246,  0.5786, -0.1456],\n",
      "        [-0.6545,  0.4841,  0.4574],\n",
      "        [-1.2400,  0.6461,  1.5168],\n",
      "        [-0.0201,  3.2841,  0.7545]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.sub(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1742, -0.9755, -0.6075,  1.2262,  1.6028])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1921])\n",
      "-0.19212159514427185\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item()) # get value as number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors bridge to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy() # numpy view to a (reference)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # data copied (value transfer)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "a = a + 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x120f85ba8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x120f98320>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-617965056ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/mktd-pytorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/mktd-pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -230.8003, -1164.6212,  -873.3654], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet architecture\n",
    "http://yann.lecun.com/exdb/lenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "leNet = Net()\n",
    "print(leNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(leNet.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.1763,  0.0460,  0.1209, -0.0257,  0.0316],\n",
      "          [-0.1940,  0.1064, -0.0153,  0.1299,  0.0409],\n",
      "          [ 0.1553, -0.1324,  0.1169, -0.1922,  0.1452],\n",
      "          [-0.1226,  0.1587, -0.0170, -0.0528,  0.1598],\n",
      "          [ 0.0723,  0.0136, -0.1449, -0.0979,  0.0180]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0098,  0.0649,  0.1186, -0.1589, -0.0252],\n",
      "          [ 0.0317,  0.1170,  0.1211, -0.1991,  0.0302],\n",
      "          [-0.0633,  0.1773,  0.1296,  0.0117, -0.0780],\n",
      "          [-0.1113,  0.1299, -0.1637,  0.0768, -0.1676],\n",
      "          [-0.1112, -0.1382, -0.1945,  0.1687, -0.1224]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0353,  0.1181,  0.0706,  0.0740, -0.1646],\n",
      "          [ 0.0570, -0.1923,  0.1263, -0.1967, -0.1574],\n",
      "          [-0.1651,  0.1093, -0.0727, -0.1736, -0.0095],\n",
      "          [-0.1713, -0.0646, -0.1810,  0.1403,  0.1088],\n",
      "          [-0.0733,  0.0346, -0.0662, -0.0883,  0.0852]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1542,  0.0151, -0.0899, -0.0306, -0.0728],\n",
      "          [ 0.0978,  0.1640, -0.0420, -0.1495,  0.0590],\n",
      "          [-0.1344,  0.0800, -0.0624,  0.1874, -0.0919],\n",
      "          [-0.1997, -0.1514, -0.1417,  0.0737, -0.0877],\n",
      "          [-0.0800, -0.1826,  0.1558,  0.1402,  0.0984]]],\n",
      "\n",
      "\n",
      "        [[[-0.0083, -0.1980, -0.0359,  0.0162, -0.1109],\n",
      "          [-0.1725, -0.0530,  0.0004,  0.0764, -0.0756],\n",
      "          [ 0.1341, -0.1019, -0.0051, -0.1836,  0.0345],\n",
      "          [-0.1048, -0.0935, -0.0959,  0.0271, -0.0778],\n",
      "          [-0.1727, -0.1313, -0.0670, -0.1264, -0.0391]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1664,  0.1310,  0.1242,  0.0952,  0.1530],\n",
      "          [ 0.0453, -0.1601,  0.1520,  0.0220, -0.0889],\n",
      "          [ 0.1211,  0.1289,  0.1873, -0.0643,  0.1359],\n",
      "          [ 0.1682, -0.0609,  0.0031,  0.0719,  0.1389],\n",
      "          [ 0.1334,  0.0166,  0.1822,  0.1037,  0.1678]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0264,  0.0804, -0.1497,  0.0510,  0.1327,  0.1694],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 6.1055e-03, -5.6950e-02,  5.8384e-02, -1.3342e-02, -7.4242e-02],\n",
      "          [ 3.7281e-03, -3.0492e-03,  1.8370e-02,  6.7181e-02, -1.3132e-03],\n",
      "          [ 6.0894e-02,  4.0949e-02, -6.3649e-02,  5.8895e-02,  2.4437e-02],\n",
      "          [-2.1222e-02, -3.8969e-02,  1.9678e-02, -2.9775e-02,  4.7123e-02],\n",
      "          [-1.4411e-02, -1.9595e-02, -2.8024e-02, -5.3365e-02,  7.5304e-02]],\n",
      "\n",
      "         [[-5.7897e-02,  1.2016e-02, -4.8121e-02,  7.3376e-02, -5.9354e-04],\n",
      "          [ 4.0597e-02, -3.0957e-02, -2.7797e-02,  2.7776e-02, -5.8715e-02],\n",
      "          [-1.1156e-02, -1.9496e-02,  3.6484e-02, -1.2706e-02,  5.4390e-02],\n",
      "          [-6.6491e-02,  7.3622e-02, -1.7291e-02,  2.1839e-02, -3.4036e-02],\n",
      "          [-3.5504e-02,  7.9740e-02,  1.5318e-04, -4.9027e-02, -7.6932e-03]],\n",
      "\n",
      "         [[ 7.3068e-02,  5.1472e-02,  4.0636e-02,  2.8675e-02, -3.4358e-02],\n",
      "          [-8.0255e-02,  5.8642e-02, -4.3161e-02,  3.0859e-02,  2.5325e-02],\n",
      "          [ 7.8851e-02, -4.5995e-02,  2.7520e-02,  2.3520e-02,  5.4464e-02],\n",
      "          [-6.8529e-02,  4.9133e-02, -6.6086e-02, -1.8015e-02,  7.3360e-02],\n",
      "          [-6.2442e-02, -5.6984e-02,  5.0468e-02, -5.3753e-02, -4.7034e-02]],\n",
      "\n",
      "         [[ 5.6112e-03, -1.9113e-02, -3.0949e-02,  2.3410e-02,  6.1685e-02],\n",
      "          [-5.0928e-02,  3.5343e-02,  6.0904e-02,  8.8096e-03,  5.3463e-02],\n",
      "          [ 4.0622e-02,  6.2238e-02,  4.6961e-02,  2.0218e-02,  6.7145e-02],\n",
      "          [-1.1660e-03,  7.1664e-02,  2.5864e-02, -2.5475e-02, -4.1966e-02],\n",
      "          [ 7.7780e-02, -4.7073e-03,  5.7402e-03, -4.1184e-02,  4.1132e-02]],\n",
      "\n",
      "         [[ 3.4757e-02, -6.5641e-02, -2.2948e-02,  4.3266e-02, -6.6103e-02],\n",
      "          [ 5.7356e-02, -7.7584e-02,  4.7323e-02, -3.6321e-02, -3.4141e-02],\n",
      "          [-8.0938e-02, -3.6806e-02, -5.8718e-02,  6.9756e-03,  6.7460e-02],\n",
      "          [-3.5278e-02, -1.3847e-02,  3.2147e-02,  6.8570e-02, -1.5825e-02],\n",
      "          [-3.2334e-02, -1.6936e-02,  2.1202e-02, -1.2709e-02, -5.7683e-02]],\n",
      "\n",
      "         [[-3.0223e-02, -6.4883e-02, -1.3992e-02,  7.7152e-02, -6.7803e-02],\n",
      "          [ 2.4068e-02,  5.2007e-02,  7.4669e-02,  7.9505e-02,  2.4422e-02],\n",
      "          [-1.2488e-02,  2.1327e-02,  5.2616e-02,  3.7678e-02, -1.0477e-02],\n",
      "          [ 5.3949e-02,  7.9351e-02, -7.0194e-02, -4.1820e-02,  1.2657e-02],\n",
      "          [ 3.1581e-02,  7.7345e-02, -5.6534e-02, -3.1743e-02,  3.8790e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3201e-02,  7.8497e-02, -6.9810e-02,  5.4314e-02, -1.4393e-02],\n",
      "          [-6.9548e-02,  6.8858e-02,  3.8637e-03,  4.6254e-02,  7.9984e-02],\n",
      "          [ 4.4120e-02,  2.2833e-02,  4.6019e-02, -1.5199e-02, -1.5190e-02],\n",
      "          [-5.9442e-02,  5.3529e-02, -1.5227e-02,  2.5807e-03,  2.9341e-02],\n",
      "          [ 1.0802e-02, -5.1693e-02,  7.8260e-02, -6.2150e-02,  8.1382e-02]],\n",
      "\n",
      "         [[ 2.1322e-02,  6.3483e-02, -5.2632e-02, -3.0423e-02,  2.5593e-02],\n",
      "          [ 3.5194e-02, -3.5835e-02, -3.2141e-02, -6.6445e-03,  6.1236e-02],\n",
      "          [ 5.5873e-02, -1.9789e-02, -4.8746e-02, -3.2070e-02, -8.4287e-03],\n",
      "          [ 6.3133e-03, -3.8998e-02,  6.2485e-02, -5.5908e-02, -4.1724e-02],\n",
      "          [ 6.6362e-02, -1.0875e-02,  7.4430e-02,  4.6101e-02, -5.6994e-02]],\n",
      "\n",
      "         [[ 3.8051e-02,  4.9648e-02,  4.0916e-02,  7.2374e-02, -5.6736e-02],\n",
      "          [-2.7568e-02,  2.0511e-02,  8.0604e-02, -7.7839e-02,  2.6662e-02],\n",
      "          [-2.2158e-02, -3.3605e-03,  3.2670e-02, -6.4255e-02,  1.8591e-02],\n",
      "          [-2.4245e-03, -8.5649e-03,  2.7245e-02,  6.5092e-02, -6.6475e-02],\n",
      "          [-2.6586e-02, -3.2120e-02, -7.6682e-02, -6.6112e-02,  8.0756e-02]],\n",
      "\n",
      "         [[-6.4281e-02,  9.3807e-03, -5.5901e-03, -2.9882e-02,  1.4101e-02],\n",
      "          [ 4.6050e-02,  5.3282e-02, -2.6981e-02, -4.5883e-02, -6.8524e-02],\n",
      "          [ 2.6731e-02,  7.8961e-02,  5.2821e-02,  3.8639e-02,  5.4875e-02],\n",
      "          [-4.1416e-02,  5.9611e-02, -6.9793e-03,  7.2150e-02, -7.4408e-02],\n",
      "          [ 6.9859e-03, -2.8788e-02, -3.6208e-02,  3.5436e-02,  4.5863e-02]],\n",
      "\n",
      "         [[ 4.3954e-02,  2.3652e-02, -4.2736e-02,  2.4341e-02, -4.6146e-02],\n",
      "          [ 7.5014e-02, -2.7177e-02, -7.8846e-02,  1.2051e-03,  7.4123e-02],\n",
      "          [-9.3729e-03, -1.0626e-02, -7.9914e-02,  6.1562e-02, -5.2458e-02],\n",
      "          [-4.9259e-02, -6.4969e-02,  4.2479e-02,  2.4091e-02, -4.7323e-02],\n",
      "          [-3.8736e-02,  3.2448e-02, -1.0804e-02, -1.6708e-02,  3.2459e-02]],\n",
      "\n",
      "         [[-4.0387e-02,  4.9350e-02, -5.5367e-02, -5.9375e-02, -7.9147e-02],\n",
      "          [ 1.4261e-02, -3.2668e-02,  2.3559e-04,  2.6501e-02,  7.6779e-02],\n",
      "          [-3.0278e-02,  4.1097e-02, -1.3275e-02, -1.9967e-02,  2.3804e-02],\n",
      "          [-3.1429e-02,  5.0368e-02,  7.3866e-02, -6.2295e-02, -3.5714e-02],\n",
      "          [ 3.9572e-02, -2.9466e-02, -7.3598e-02,  7.9526e-02,  4.6625e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7237e-02,  6.2515e-02, -5.3328e-02,  3.8796e-02,  3.9709e-02],\n",
      "          [-1.8915e-03,  5.7243e-02,  1.4730e-02, -4.8091e-02, -6.4970e-02],\n",
      "          [-2.5964e-02, -2.2647e-03,  2.1253e-02,  6.2687e-02, -7.2510e-02],\n",
      "          [-3.4854e-03,  6.1808e-02, -3.1276e-03, -6.1321e-02, -2.9838e-02],\n",
      "          [ 6.5692e-02,  6.9169e-02,  4.9266e-02, -2.2019e-03, -3.4949e-02]],\n",
      "\n",
      "         [[-4.7594e-02, -2.4809e-03,  3.2131e-02, -2.8529e-02, -5.6570e-02],\n",
      "          [-2.3999e-02, -2.3151e-02, -1.1256e-02, -4.4091e-02, -4.4569e-02],\n",
      "          [-4.8401e-02,  1.3121e-02, -7.7754e-02, -6.0101e-02, -4.0600e-02],\n",
      "          [-7.4345e-02, -2.6268e-02,  4.5456e-02, -8.1417e-02,  3.2589e-02],\n",
      "          [ 7.5767e-02,  1.1166e-02, -3.9661e-02, -3.3466e-02,  1.9568e-02]],\n",
      "\n",
      "         [[ 1.4702e-02, -1.4175e-02, -7.7450e-02,  2.0213e-02,  5.8355e-02],\n",
      "          [-7.8653e-02,  7.0717e-02,  2.9477e-02,  7.7764e-02, -1.5194e-02],\n",
      "          [-3.7046e-02, -2.1880e-02, -2.7034e-02, -1.8722e-02,  7.1005e-02],\n",
      "          [ 1.7314e-02, -5.2030e-02,  4.3511e-02,  7.4465e-02, -1.5363e-02],\n",
      "          [-1.4907e-02, -2.2585e-02,  2.2346e-02, -4.7149e-02, -5.4629e-02]],\n",
      "\n",
      "         [[ 1.9800e-02,  2.8192e-02,  4.8249e-02,  1.0379e-02, -4.8655e-02],\n",
      "          [ 2.3713e-02,  1.0150e-02,  1.1849e-02,  7.8934e-02, -4.4281e-02],\n",
      "          [-7.7825e-02,  5.0305e-02, -7.9471e-02,  4.4053e-02,  5.2681e-02],\n",
      "          [-5.7743e-02, -6.2732e-02,  1.9407e-02,  2.2995e-02, -7.3043e-02],\n",
      "          [ 1.3196e-02,  3.3219e-02,  3.1068e-02, -7.8792e-03, -2.2267e-02]],\n",
      "\n",
      "         [[ 4.2773e-02,  3.5440e-02,  1.6272e-02, -7.9210e-02,  1.9975e-02],\n",
      "          [-5.2570e-02,  2.0866e-02, -2.7185e-03,  6.5893e-02, -2.3256e-02],\n",
      "          [ 2.6592e-02,  6.4210e-02,  8.1550e-02,  7.1721e-02, -5.3717e-02],\n",
      "          [-6.8195e-02,  6.2496e-02,  4.1310e-02, -8.0238e-02, -4.7994e-02],\n",
      "          [ 4.1686e-02,  2.1759e-03,  7.3867e-02,  4.9900e-02, -5.4630e-02]],\n",
      "\n",
      "         [[-7.8404e-02, -5.8897e-02, -2.0370e-02,  3.8327e-02, -5.9012e-02],\n",
      "          [ 6.5707e-02, -1.8969e-02, -6.3774e-02, -3.9847e-02,  1.4900e-02],\n",
      "          [-5.0533e-02,  4.6357e-03,  5.5684e-02,  7.9969e-02, -5.2900e-02],\n",
      "          [ 5.4058e-03,  3.6619e-02,  3.9031e-03,  8.1428e-02,  5.1575e-02],\n",
      "          [ 7.4322e-02, -2.1570e-02,  5.8946e-02,  6.9925e-02, -7.9520e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1312e-02, -3.6266e-02, -7.7333e-03, -5.2484e-02, -5.5584e-03],\n",
      "          [ 5.4457e-02,  2.4249e-02, -4.8987e-02,  6.2450e-03,  7.0259e-02],\n",
      "          [-2.7371e-02,  5.3386e-03,  7.7325e-03,  6.0314e-02,  8.6272e-03],\n",
      "          [-4.8201e-02,  5.0874e-02,  6.7762e-02,  4.3511e-02,  2.6044e-02],\n",
      "          [-4.7186e-02, -6.8728e-02, -7.2714e-02, -2.6435e-02, -3.6119e-02]],\n",
      "\n",
      "         [[-4.6024e-02, -1.1575e-02, -2.0625e-02, -3.6950e-02,  1.1365e-02],\n",
      "          [ 2.3417e-02, -6.7250e-02, -1.1503e-02, -4.4822e-02,  1.0613e-02],\n",
      "          [ 7.7152e-02,  3.6954e-02, -1.2643e-02, -4.7995e-02, -5.0796e-02],\n",
      "          [ 7.1201e-02, -4.3342e-03,  2.7973e-02, -6.5367e-02, -6.1177e-02],\n",
      "          [-6.7960e-03,  1.9924e-02, -5.2038e-02, -4.6710e-02, -4.0884e-02]],\n",
      "\n",
      "         [[-6.1712e-02,  6.2528e-02, -5.8514e-02,  5.1996e-02,  6.1912e-02],\n",
      "          [ 6.9629e-02,  6.7236e-02, -7.4052e-02, -3.9219e-02,  8.1026e-02],\n",
      "          [-5.0206e-02,  1.9842e-02, -4.6516e-02,  2.6269e-02, -5.8424e-02],\n",
      "          [-4.9194e-02,  1.6229e-02,  2.8289e-02,  6.0913e-02, -5.2102e-02],\n",
      "          [ 2.7957e-02, -6.4633e-03,  3.4913e-02, -3.1751e-02, -7.7710e-02]],\n",
      "\n",
      "         [[ 2.7498e-02,  6.4002e-02,  6.9049e-02, -2.3870e-02, -5.1413e-02],\n",
      "          [-2.3686e-02, -3.3700e-02, -6.4002e-02, -3.3889e-02,  6.6132e-02],\n",
      "          [ 6.6151e-02, -5.1177e-02,  5.5423e-03,  1.7452e-02, -7.2919e-02],\n",
      "          [-5.2062e-02,  7.2609e-02,  7.4098e-03,  4.4347e-03, -8.1031e-02],\n",
      "          [-5.0136e-02,  4.4196e-02, -7.9117e-02,  6.1735e-02,  1.1025e-02]],\n",
      "\n",
      "         [[ 3.4592e-02,  1.1487e-02,  5.2373e-02,  9.1248e-03,  6.9243e-02],\n",
      "          [-2.3271e-02,  7.1653e-02, -7.4925e-02, -6.3928e-02, -2.2234e-02],\n",
      "          [-2.9205e-02, -1.7638e-02,  4.7284e-02,  4.8353e-03, -7.9810e-02],\n",
      "          [-2.9593e-02,  3.3682e-02, -5.9601e-02, -2.2209e-02, -2.4424e-02],\n",
      "          [ 5.9780e-02, -7.4540e-02,  1.3083e-02,  6.1228e-02,  5.0375e-02]],\n",
      "\n",
      "         [[-6.8682e-02, -6.1832e-02,  6.6762e-02, -7.0020e-02, -6.1562e-02],\n",
      "          [-4.4596e-02, -9.1099e-03, -5.4274e-02,  6.4867e-02, -2.8510e-02],\n",
      "          [-6.4573e-02, -1.3361e-02,  7.3062e-02, -1.4210e-02,  6.5535e-02],\n",
      "          [ 5.4849e-02, -3.4102e-02, -2.5189e-02, -2.4494e-02, -8.0091e-02],\n",
      "          [-6.4630e-02,  7.3553e-02, -6.4300e-02, -6.2824e-02, -3.3099e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0546e-02, -6.7965e-02,  6.4219e-02, -2.7015e-02,  3.4418e-02],\n",
      "          [ 3.6200e-02, -5.7205e-02, -6.1144e-02, -1.5439e-02, -8.9468e-03],\n",
      "          [-5.7056e-02, -6.3050e-02, -6.3811e-02,  7.4645e-02, -8.8420e-03],\n",
      "          [-4.8962e-02,  1.3669e-02,  1.2070e-02, -1.4645e-02,  7.6418e-03],\n",
      "          [-6.4024e-02, -5.5545e-02,  3.1133e-02,  6.2358e-02,  3.5074e-04]],\n",
      "\n",
      "         [[ 6.0986e-02,  2.4199e-02,  3.8733e-02,  6.1657e-02, -2.8614e-02],\n",
      "          [ 5.6604e-02,  3.1882e-02, -3.5180e-02, -8.0864e-02,  4.5778e-02],\n",
      "          [-4.2417e-02,  5.0045e-02, -1.6369e-02, -4.3183e-02, -1.0463e-02],\n",
      "          [ 8.0429e-02,  5.4207e-02, -1.5863e-02, -6.3545e-02,  7.9086e-02],\n",
      "          [ 6.8782e-02,  7.1390e-02, -2.2017e-02,  3.8711e-02, -8.0189e-02]],\n",
      "\n",
      "         [[-8.0015e-02,  5.6190e-02, -8.3908e-03, -4.0588e-02,  7.1241e-04],\n",
      "          [-2.3437e-02,  4.4830e-02, -7.8879e-02, -2.1743e-02, -5.2299e-03],\n",
      "          [ 6.8002e-02,  8.1344e-02,  9.7889e-03, -1.4848e-02,  2.2926e-02],\n",
      "          [-1.9567e-02, -6.9130e-02, -6.0114e-02, -4.0794e-02, -1.6322e-02],\n",
      "          [-1.2175e-02,  2.2042e-02,  3.2186e-02,  1.8181e-02, -3.9714e-02]],\n",
      "\n",
      "         [[-6.7056e-02, -6.5117e-03,  7.5391e-02,  4.6532e-02, -5.0688e-02],\n",
      "          [-6.9235e-02,  1.5485e-02, -3.3140e-03, -3.6155e-02,  1.5656e-02],\n",
      "          [-4.4435e-02, -3.8660e-02,  3.8802e-02, -5.4711e-02,  9.0620e-03],\n",
      "          [-5.8303e-03,  5.7847e-02,  3.5516e-02,  1.6568e-02, -7.1038e-02],\n",
      "          [ 5.4322e-02,  7.2791e-02,  7.9807e-02, -2.9850e-02,  5.0710e-02]],\n",
      "\n",
      "         [[-1.2637e-02,  1.1573e-02, -1.6945e-02,  6.2192e-02, -5.7692e-03],\n",
      "          [ 6.1133e-02,  2.3888e-02,  7.1647e-02, -5.1885e-02, -9.4377e-03],\n",
      "          [-5.1272e-02,  7.0098e-02, -7.3352e-02,  4.3012e-02, -2.3892e-02],\n",
      "          [ 4.5002e-02,  8.0374e-03, -2.7842e-02,  5.4674e-02,  6.8959e-02],\n",
      "          [ 3.7611e-02,  6.6772e-02,  3.2281e-02,  1.0999e-02,  7.5615e-02]],\n",
      "\n",
      "         [[-2.4723e-02, -4.8733e-02,  3.4005e-02,  5.3888e-02,  2.5847e-02],\n",
      "          [ 6.5594e-02,  5.5396e-02, -1.0295e-02, -5.4124e-02,  2.5818e-02],\n",
      "          [-1.5511e-02,  1.8544e-02,  6.0044e-03,  3.6810e-02, -4.3996e-02],\n",
      "          [ 7.4661e-02, -6.8924e-02,  3.9016e-02,  1.8358e-02,  6.3217e-02],\n",
      "          [ 6.1809e-02,  3.2665e-02,  6.9314e-02,  7.2932e-02,  7.0954e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1508e-02,  7.1450e-02, -5.7865e-03,  4.4953e-02, -8.1476e-02],\n",
      "          [-1.3785e-02,  4.3355e-02, -5.5482e-02, -8.8227e-03,  5.2164e-02],\n",
      "          [-8.0576e-02,  2.0894e-02, -7.9451e-02,  7.0729e-02, -6.9198e-02],\n",
      "          [-2.7722e-02,  1.1688e-02, -5.1157e-02,  3.2727e-02,  2.1532e-02],\n",
      "          [ 6.1791e-02, -1.9257e-02,  1.5932e-02,  3.6382e-02, -6.0124e-02]],\n",
      "\n",
      "         [[ 2.1449e-02, -2.1304e-02,  4.5824e-02,  3.8017e-02,  1.8429e-02],\n",
      "          [ 1.9420e-02,  7.8556e-02, -5.8437e-02,  6.4153e-03,  3.3317e-02],\n",
      "          [-4.8831e-02,  5.4580e-03, -5.4712e-02,  4.6282e-03,  7.4179e-02],\n",
      "          [-4.0210e-02, -2.9059e-02,  2.8104e-02, -3.0852e-02, -4.1595e-03],\n",
      "          [-7.9831e-02, -1.1323e-02, -2.3194e-02,  1.2069e-02, -1.3585e-02]],\n",
      "\n",
      "         [[ 3.4890e-03,  1.0016e-02, -5.4877e-02,  5.0028e-02, -4.4562e-02],\n",
      "          [-8.1601e-02,  3.3710e-02,  6.7132e-02, -2.5629e-02,  5.3815e-02],\n",
      "          [-7.9826e-03,  4.6078e-02, -7.7066e-03,  4.1284e-02, -1.4800e-02],\n",
      "          [ 3.4137e-02,  3.0654e-02, -3.1870e-02,  6.3691e-02, -7.6803e-02],\n",
      "          [ 5.9423e-02, -8.1520e-02, -7.3621e-02,  5.5342e-02,  7.9605e-03]],\n",
      "\n",
      "         [[-3.6627e-03,  3.5366e-02, -5.2540e-02, -1.5382e-02, -3.5687e-03],\n",
      "          [-3.1698e-02, -2.2551e-02, -6.8821e-02, -7.0537e-02, -6.8942e-02],\n",
      "          [-4.9400e-02,  6.3471e-02, -7.3893e-02, -5.5903e-02,  2.2396e-02],\n",
      "          [ 2.9048e-02, -5.2829e-02,  7.8477e-02,  4.9261e-02, -4.7362e-02],\n",
      "          [ 2.7867e-02, -8.4850e-03, -3.9797e-02, -7.0430e-02,  2.6340e-02]],\n",
      "\n",
      "         [[ 1.0096e-05, -6.2704e-02,  3.6772e-02, -6.1722e-02,  1.0229e-02],\n",
      "          [-8.1558e-02,  2.1601e-02, -3.6306e-03, -1.7505e-02, -2.6064e-02],\n",
      "          [-3.3315e-02,  4.1536e-02, -4.1711e-02, -4.3291e-02, -1.0834e-03],\n",
      "          [-3.3149e-02,  3.6866e-02, -2.6257e-02,  4.5708e-02, -9.8188e-03],\n",
      "          [ 2.8507e-02,  2.9132e-02, -3.9345e-02,  7.5433e-02,  7.1869e-02]],\n",
      "\n",
      "         [[ 4.4341e-02, -1.1597e-02,  6.5656e-03, -1.7776e-02, -2.7544e-02],\n",
      "          [ 2.2086e-03,  2.4500e-02,  5.2680e-02, -6.6965e-02,  3.6817e-02],\n",
      "          [ 1.4501e-02,  4.1939e-02, -3.8135e-02, -4.9079e-02, -1.2365e-02],\n",
      "          [-1.5610e-02, -7.4166e-02, -7.8431e-02, -2.6011e-02, -2.4491e-02],\n",
      "          [ 7.1100e-02, -7.4697e-02,  1.3824e-03, -3.0626e-02, -7.1189e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0313, -0.0100,  0.0170,  0.0656,  0.0685, -0.0489, -0.0617, -0.0286,\n",
      "         0.0507,  0.0051, -0.0724, -0.0683,  0.0063,  0.0527, -0.0084,  0.0675],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0368, -0.0027,  0.0270,  ...,  0.0282, -0.0440,  0.0031],\n",
      "        [-0.0301,  0.0295, -0.0255,  ..., -0.0283,  0.0226, -0.0140],\n",
      "        [-0.0070, -0.0022,  0.0255,  ...,  0.0413,  0.0208, -0.0447],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0081, -0.0233,  ..., -0.0194,  0.0391, -0.0298],\n",
      "        [ 0.0105,  0.0045, -0.0228,  ..., -0.0042,  0.0372, -0.0380],\n",
      "        [-0.0179, -0.0316, -0.0430,  ...,  0.0187, -0.0213,  0.0180]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0243,  0.0420,  0.0058, -0.0069,  0.0067, -0.0210,  0.0190,  0.0413,\n",
      "        -0.0415,  0.0086,  0.0049,  0.0330,  0.0271, -0.0078, -0.0290,  0.0361,\n",
      "        -0.0149, -0.0045,  0.0345, -0.0261,  0.0295,  0.0477, -0.0127,  0.0184,\n",
      "        -0.0421, -0.0070, -0.0158, -0.0220,  0.0364,  0.0436,  0.0371,  0.0030,\n",
      "        -0.0434,  0.0075,  0.0091, -0.0185,  0.0300,  0.0390, -0.0094,  0.0334,\n",
      "         0.0168,  0.0411, -0.0152,  0.0453, -0.0190,  0.0154,  0.0114,  0.0267,\n",
      "         0.0079, -0.0490, -0.0049,  0.0238, -0.0246,  0.0096,  0.0377,  0.0173,\n",
      "        -0.0347,  0.0389, -0.0295, -0.0318, -0.0050,  0.0110,  0.0128,  0.0303,\n",
      "         0.0166, -0.0281,  0.0170,  0.0067,  0.0326,  0.0329,  0.0467, -0.0189,\n",
      "        -0.0143, -0.0256, -0.0392, -0.0469, -0.0083,  0.0437,  0.0444, -0.0498,\n",
      "        -0.0231, -0.0080, -0.0443,  0.0099, -0.0278, -0.0384, -0.0036,  0.0161,\n",
      "         0.0453,  0.0088,  0.0249,  0.0048, -0.0411,  0.0116,  0.0297,  0.0262,\n",
      "        -0.0318,  0.0042, -0.0153, -0.0076,  0.0043, -0.0115,  0.0201,  0.0027,\n",
      "        -0.0462,  0.0266, -0.0316, -0.0355, -0.0441, -0.0380, -0.0157, -0.0141,\n",
      "         0.0138,  0.0465,  0.0364, -0.0480, -0.0054, -0.0306, -0.0008,  0.0389],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0028,  0.0327,  0.0362,  ..., -0.0313, -0.0728, -0.0144],\n",
      "        [-0.0285,  0.0270, -0.0298,  ...,  0.0358, -0.0547,  0.0832],\n",
      "        [ 0.0337, -0.0038, -0.0019,  ...,  0.0590,  0.0686, -0.0001],\n",
      "        ...,\n",
      "        [ 0.0600,  0.0765, -0.0204,  ...,  0.0616,  0.0395,  0.0222],\n",
      "        [ 0.0274,  0.0520,  0.0399,  ..., -0.0907, -0.0135,  0.0714],\n",
      "        [-0.0827, -0.0859, -0.0646,  ..., -0.0491, -0.0148, -0.0534]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0182,  0.0599,  0.0749, -0.0078, -0.0598,  0.0212,  0.0427,  0.0751,\n",
      "        -0.0393,  0.0196, -0.0026, -0.0081, -0.0556, -0.0251, -0.0500, -0.0468,\n",
      "        -0.0472, -0.0280, -0.0865,  0.0290,  0.0482,  0.0528, -0.0594, -0.0037,\n",
      "        -0.0834, -0.0685, -0.0029, -0.0285, -0.0841,  0.0753,  0.0060, -0.0195,\n",
      "         0.0223, -0.0132,  0.0154, -0.0351,  0.0620, -0.0585, -0.0377,  0.0231,\n",
      "         0.0779, -0.0344, -0.0851, -0.0086,  0.0492,  0.0762,  0.0636, -0.0358,\n",
      "        -0.0885,  0.0699, -0.0034,  0.0368,  0.0813, -0.0144, -0.0353,  0.0470,\n",
      "        -0.0058,  0.0342,  0.0401,  0.0685,  0.0518, -0.0176,  0.0527, -0.0738,\n",
      "        -0.0719,  0.0903,  0.0782,  0.0484,  0.0755, -0.0225,  0.0499, -0.0558,\n",
      "         0.0446,  0.0812,  0.0624,  0.0314, -0.0763,  0.0217,  0.0543,  0.0559,\n",
      "        -0.0409,  0.0825, -0.0716,  0.0894], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0887, -0.0558, -0.0065, -0.0377, -0.0028, -0.0698, -0.0818,  0.0881,\n",
      "          0.0249, -0.0129,  0.0137, -0.0750,  0.0886,  0.0956,  0.0650, -0.0802,\n",
      "          0.0357, -0.0534,  0.0917,  0.0181,  0.1037,  0.0981, -0.0405, -0.0401,\n",
      "         -0.0377, -0.0642, -0.0439,  0.0075,  0.0691, -0.0938, -0.0946,  0.0339,\n",
      "          0.0503,  0.0888, -0.0516, -0.0016,  0.0311,  0.0797,  0.0149, -0.0558,\n",
      "          0.0716, -0.0730, -0.0238,  0.0736,  0.0233,  0.0567,  0.0076, -0.0103,\n",
      "         -0.0655,  0.0485, -0.0022,  0.0292, -0.0462,  0.0121,  0.0179,  0.0604,\n",
      "          0.0835,  0.0478, -0.0915,  0.0371, -0.0518,  0.0105, -0.0362, -0.0599,\n",
      "         -0.0511,  0.0893, -0.0325,  0.0203, -0.0903,  0.0787, -0.0533, -0.0362,\n",
      "          0.0228,  0.0302,  0.0670, -0.1044,  0.0299,  0.0793,  0.0032,  0.0716,\n",
      "          0.0231, -0.0818,  0.0526, -0.0908],\n",
      "        [ 0.0477,  0.0207,  0.0079, -0.0918,  0.1000, -0.0937,  0.0408,  0.0427,\n",
      "         -0.1022, -0.1016, -0.0787,  0.0325,  0.0794, -0.0130, -0.0629,  0.0033,\n",
      "         -0.0857,  0.0973,  0.0031, -0.0749, -0.0307, -0.0854,  0.0515,  0.0691,\n",
      "         -0.0572, -0.0620,  0.0163, -0.0066, -0.0972, -0.0046,  0.0531, -0.0038,\n",
      "         -0.1074, -0.0164,  0.0248,  0.0240,  0.0077,  0.0838,  0.0905,  0.0363,\n",
      "          0.0413, -0.0888, -0.0708,  0.0433, -0.0134,  0.0253, -0.0522, -0.0153,\n",
      "          0.0854, -0.0395, -0.0855, -0.0422, -0.0768, -0.0847, -0.0728, -0.0478,\n",
      "          0.1046,  0.0894, -0.0584,  0.0062,  0.0828, -0.0115, -0.0687,  0.0646,\n",
      "          0.0329,  0.0662, -0.0038,  0.0549, -0.0243,  0.0006,  0.0840,  0.0295,\n",
      "         -0.0559, -0.0347,  0.0411,  0.1087,  0.0516,  0.0713, -0.0115, -0.0263,\n",
      "         -0.0828,  0.1038, -0.0578,  0.0116],\n",
      "        [ 0.0541, -0.0083,  0.0534,  0.0603, -0.0673, -0.0341, -0.0038, -0.0034,\n",
      "         -0.0620,  0.0574,  0.0184,  0.0629, -0.1051,  0.0661, -0.0449,  0.0027,\n",
      "          0.0721,  0.0064,  0.1089,  0.0706,  0.0141, -0.1079,  0.0197,  0.0085,\n",
      "         -0.0092,  0.0819, -0.0874,  0.0812,  0.0829, -0.0646,  0.1053, -0.0150,\n",
      "         -0.0968,  0.0045, -0.0975, -0.0155,  0.0536,  0.0663,  0.0960,  0.1014,\n",
      "         -0.0013,  0.0962, -0.0736,  0.0725, -0.0583, -0.0801, -0.0587, -0.0075,\n",
      "         -0.0043,  0.0967, -0.0294, -0.0582,  0.0607,  0.0045,  0.0856, -0.0142,\n",
      "         -0.0241,  0.0916,  0.0360, -0.0839, -0.0734,  0.0942, -0.0428,  0.0478,\n",
      "          0.0920,  0.0044, -0.0304, -0.0982,  0.0653,  0.0408, -0.0205,  0.0377,\n",
      "          0.0752, -0.0617,  0.0882, -0.0287,  0.0401,  0.0915,  0.0170, -0.0440,\n",
      "         -0.0964,  0.0741, -0.0889, -0.0089],\n",
      "        [ 0.0118,  0.0338, -0.0907, -0.0741,  0.1011,  0.0316,  0.0544, -0.0435,\n",
      "         -0.0355, -0.0608,  0.0240, -0.0969, -0.0785, -0.0326, -0.1001,  0.1084,\n",
      "         -0.0845, -0.0802,  0.0448,  0.0603,  0.0536, -0.0599, -0.0836, -0.0791,\n",
      "         -0.1016,  0.0840, -0.0110, -0.0481,  0.0852, -0.0566, -0.0531,  0.0350,\n",
      "          0.0737,  0.0069, -0.0338,  0.0760,  0.0196, -0.0032, -0.0703, -0.0716,\n",
      "          0.0694,  0.0709,  0.1065,  0.0813,  0.0429,  0.0452,  0.0827, -0.0935,\n",
      "         -0.0549, -0.0608,  0.0708, -0.0660, -0.0206, -0.0482,  0.0784, -0.0956,\n",
      "         -0.0868, -0.0636, -0.0061,  0.0094,  0.0400,  0.0907,  0.0177, -0.0527,\n",
      "          0.0289, -0.0027, -0.1077, -0.1029,  0.0093, -0.0780,  0.0988, -0.0833,\n",
      "         -0.0633,  0.0339, -0.1061,  0.0617, -0.0627,  0.0023, -0.0565,  0.0223,\n",
      "         -0.0060, -0.0599, -0.0287,  0.1014],\n",
      "        [-0.0121, -0.0110, -0.0344,  0.0732, -0.0469, -0.0927,  0.0794,  0.1048,\n",
      "         -0.0810,  0.0262,  0.0472, -0.1008,  0.0722,  0.0833, -0.0173,  0.0457,\n",
      "         -0.0773, -0.0468, -0.0795, -0.0274, -0.0881, -0.1029,  0.0597,  0.0791,\n",
      "         -0.0201,  0.0447,  0.0080, -0.0844,  0.0474, -0.0551,  0.0688,  0.0476,\n",
      "         -0.0901,  0.0672, -0.0347, -0.0447, -0.0928,  0.0876, -0.0481,  0.0697,\n",
      "         -0.0306,  0.0812,  0.0369, -0.0525, -0.0339, -0.0259,  0.1058,  0.0450,\n",
      "         -0.0495, -0.0368,  0.0284, -0.0054, -0.0588,  0.0018, -0.0181, -0.0625,\n",
      "         -0.0437,  0.0243,  0.1032, -0.1034,  0.0118, -0.0425, -0.0062, -0.0092,\n",
      "          0.0819,  0.0227,  0.0822,  0.0422,  0.0552,  0.1020, -0.0351, -0.0469,\n",
      "          0.0183,  0.0334, -0.0323,  0.0970,  0.0551, -0.0876, -0.0594, -0.0215,\n",
      "         -0.0034,  0.0044,  0.0010,  0.0877],\n",
      "        [-0.0487, -0.0758,  0.0440,  0.0824, -0.0036, -0.1088, -0.0157,  0.0117,\n",
      "         -0.0610, -0.0665, -0.0585, -0.0006, -0.0944,  0.0666,  0.0328,  0.1045,\n",
      "          0.0741, -0.0934, -0.0682,  0.0902, -0.0762,  0.0454,  0.0463,  0.0556,\n",
      "         -0.0765, -0.1054, -0.0769,  0.0029,  0.0255, -0.0638,  0.0348,  0.1049,\n",
      "         -0.0854, -0.0062, -0.0391, -0.0724, -0.0458,  0.0871, -0.0705,  0.1039,\n",
      "          0.0380,  0.0654, -0.0143,  0.0719, -0.0625, -0.0341, -0.0462,  0.0974,\n",
      "         -0.0239, -0.0650, -0.1086, -0.0510,  0.1079,  0.0940, -0.0050, -0.0441,\n",
      "          0.1068,  0.0668,  0.0373, -0.1078, -0.0134, -0.0600,  0.0849,  0.0829,\n",
      "         -0.0423,  0.0722, -0.0939,  0.1053, -0.0366,  0.0085,  0.0591, -0.0459,\n",
      "          0.0444, -0.0340, -0.0948,  0.0855, -0.0239,  0.0559, -0.0742,  0.1023,\n",
      "         -0.0160, -0.0076, -0.0101,  0.0596],\n",
      "        [ 0.0740,  0.0667,  0.0605,  0.0922,  0.0995, -0.0474,  0.1030, -0.0902,\n",
      "          0.0660,  0.1087, -0.0027,  0.0384,  0.0690,  0.0456, -0.0104,  0.1077,\n",
      "         -0.0204,  0.0583, -0.0400, -0.0645, -0.0251, -0.0611,  0.0622,  0.0386,\n",
      "          0.0366, -0.0203,  0.0845,  0.0883,  0.0524,  0.0483,  0.0812,  0.0457,\n",
      "         -0.0331,  0.0344,  0.0717,  0.0955, -0.0871, -0.1003,  0.0664, -0.0920,\n",
      "          0.0312,  0.0493,  0.0348, -0.0725, -0.0129, -0.0165, -0.0044, -0.0416,\n",
      "          0.0750,  0.0489,  0.0815, -0.0497,  0.0457,  0.0964, -0.0974, -0.0251,\n",
      "         -0.0732, -0.0201, -0.0242,  0.0826, -0.0723, -0.0637, -0.0254, -0.0425,\n",
      "          0.0315, -0.0348,  0.0921,  0.0390,  0.0124,  0.0233, -0.0757, -0.0320,\n",
      "          0.0833, -0.0230,  0.1071, -0.0588, -0.1070, -0.0443, -0.0883,  0.0115,\n",
      "         -0.0642,  0.0300,  0.0911, -0.0291],\n",
      "        [-0.0294,  0.0885, -0.0937, -0.0485,  0.0415, -0.0502,  0.0319, -0.0758,\n",
      "         -0.0014, -0.0291, -0.0213,  0.0214,  0.0835, -0.0639,  0.0911, -0.0326,\n",
      "         -0.1075,  0.0551,  0.0886,  0.0991,  0.0930, -0.0306, -0.0046,  0.0779,\n",
      "         -0.0098, -0.1007,  0.0457, -0.0090,  0.0754, -0.0015, -0.0592,  0.0396,\n",
      "         -0.0607,  0.0854,  0.0761,  0.0808,  0.0845, -0.0506,  0.0295, -0.0619,\n",
      "         -0.0968,  0.0740,  0.0049, -0.0498, -0.1060, -0.1030,  0.0874, -0.0461,\n",
      "         -0.0723,  0.0514, -0.0267, -0.0117, -0.0859, -0.0307,  0.1045, -0.0985,\n",
      "          0.0086,  0.0515,  0.0247,  0.0256, -0.0842,  0.0132, -0.0693, -0.1031,\n",
      "         -0.0564, -0.0773,  0.0568,  0.0988,  0.0331,  0.0984, -0.0821,  0.0416,\n",
      "         -0.0315, -0.0239,  0.0781,  0.0549,  0.0212,  0.0367, -0.0750, -0.0677,\n",
      "         -0.0130,  0.0183, -0.1046, -0.0805],\n",
      "        [-0.0978, -0.0783,  0.0392, -0.1076,  0.0636, -0.0576, -0.0651,  0.0595,\n",
      "         -0.1070,  0.0991, -0.0512,  0.0359,  0.0395, -0.0408,  0.0679,  0.0514,\n",
      "         -0.0509, -0.0119, -0.0947,  0.0801,  0.0012, -0.0901, -0.0244, -0.0619,\n",
      "          0.0282, -0.0888,  0.0213, -0.0164, -0.0942, -0.0158,  0.0406, -0.0607,\n",
      "          0.0525,  0.0195,  0.0377,  0.0861,  0.0795,  0.0755,  0.0973,  0.0764,\n",
      "          0.0647,  0.0732, -0.0654, -0.0953, -0.0717,  0.1005, -0.0156, -0.0652,\n",
      "         -0.0069,  0.0820,  0.0943,  0.0737, -0.0697, -0.0006,  0.1071,  0.0787,\n",
      "         -0.0796, -0.0182,  0.0479,  0.0406,  0.0916, -0.0623,  0.0576, -0.0801,\n",
      "          0.0303,  0.0424,  0.0055, -0.0824, -0.0954, -0.0005, -0.0598, -0.0141,\n",
      "          0.0277,  0.0170, -0.0507,  0.0812,  0.0815,  0.0592,  0.0095,  0.0568,\n",
      "          0.0586,  0.0186, -0.0012,  0.0986],\n",
      "        [ 0.0671,  0.0142, -0.0791,  0.0437,  0.0716,  0.0145, -0.0892, -0.0508,\n",
      "         -0.0843, -0.0254, -0.0432, -0.1003,  0.0458,  0.0440, -0.0396, -0.0756,\n",
      "         -0.0764,  0.0398, -0.0217,  0.0758, -0.0306,  0.0440, -0.0985,  0.1050,\n",
      "          0.0587, -0.0586, -0.0313,  0.0097, -0.0891,  0.0489,  0.0380, -0.0528,\n",
      "          0.0925,  0.0828,  0.0949,  0.0913, -0.0970, -0.0975, -0.0003, -0.0660,\n",
      "          0.0500, -0.0963,  0.0264,  0.1007, -0.0994,  0.0929,  0.0495,  0.0098,\n",
      "         -0.0464, -0.0125,  0.0722, -0.0575,  0.0209, -0.0710,  0.0029, -0.0321,\n",
      "          0.0762,  0.0623, -0.0501, -0.0091, -0.0082,  0.0963,  0.0761,  0.0391,\n",
      "          0.0416,  0.0720, -0.1074, -0.0097,  0.0713,  0.1008,  0.0212,  0.0678,\n",
      "          0.0616,  0.0855,  0.0610, -0.0697,  0.0891, -0.0486, -0.0908,  0.0491,\n",
      "          0.0339,  0.0239,  0.0930, -0.0092]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0133, -0.0261,  0.0717, -0.0288,  0.1060,  0.0702, -0.0992,  0.0280,\n",
      "        -0.0499, -0.0626], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0217, -0.0229,  0.0645, -0.1187,  0.1667,  0.0362, -0.0968,  0.0205,\n",
      "          0.0042, -0.1033]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = leNet(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(leNet.state_dict(), './leNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherNet = Net()\n",
    "anotherNet.load_state_dict(torch.load('./leNet.h5'))\n",
    "anotherNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.3533, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32) # random input\n",
    "output = leNet(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x127a078d0>\n",
      "<AddmmBackward object at 0x127a07940>\n",
      "<AccumulateGrad object at 0x127a078d0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0111, -0.0038, -0.0115, -0.0072, -0.0006,  0.0181])\n"
     ]
    }
   ],
   "source": [
    "leNet.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(leNet.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(leNet.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "# optimizer = optim.SGD(leNet.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(leNet.parameters(), lr=2e-3)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = leNet(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/loading during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "stamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%dT%H.%M.%S')\n",
    "torch.save({\n",
    "            'epoch': 1,\n",
    "            'model_state_dict': leNet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'checkpoint-{}.last'.format(stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(leNet.parameters(), lr=0.01)\n",
    "\n",
    "checkpoint = torch.load('checkpoint-{}.last'.format(stamp))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset\n",
    "\n",
    "Remember lesson 1?\n",
    "\n",
    "#### Loading MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_path = './data'\n",
    "\n",
    "#trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=data_path, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=data_path, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 32, 32])\n",
      "1\n",
      "<class 'torch.Tensor'> torch.Size([32, 1, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "sample = train_set[random.randint(1,len(train_set))]\n",
    "print(type(sample[0]), sample[0].shape)\n",
    "print(sample[1].item())\n",
    "\n",
    "tensor_image = sample[0].view(sample[0].shape[2], sample[0].shape[0], sample[0].shape[1])\n",
    "print(type(tensor_image), tensor_image.shape)\n",
    "\n",
    "tensor_image = torch.squeeze(tensor_image)\n",
    "\n",
    "plt.imshow(tensor_image, cmap='gray', interpolation='none')\n",
    "plt.title(\"Ground Truth: {}\".format(sample[1].item()))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_imshow_data(data):\n",
    "    data = np.asarray(data)\n",
    "    if data.ndim == 2:\n",
    "        return True\n",
    "    elif data.ndim == 3:\n",
    "        if 3 <= data.shape[2] <= 4:\n",
    "            return True\n",
    "        else:\n",
    "            print('The \"data\" has 3 dimensions but the last dimension '\n",
    "                  'must have a length of 3 (RGB) or 4 (RGBA), not \"{}\".'\n",
    "                  ''.format(data.shape[2]))\n",
    "            return False\n",
    "    else:\n",
    "        print('To visualize an image the data must be 2 dimensional or '\n",
    "              '3 dimensional, not \"{}\".'\n",
    "              ''.format(data.ndim))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import face\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "np_image = face()\n",
    "print(type(np_image), np_image.shape)\n",
    "tensor_image = torch.from_numpy(np_image)\n",
    "print(type(tensor_image), tensor_image.shape)\n",
    "# reshape to channel first:\n",
    "tensor_image = tensor_image.view(tensor_image.shape[2], tensor_image.shape[0], tensor_image.shape[1])\n",
    "print(type(tensor_image), tensor_image.shape)\n",
    "\n",
    "# If you try to plot image with shape (C, H, W)\n",
    "# You will get TypeError:\n",
    "# plt.imshow(tensor_image)\n",
    "\n",
    "# So we need to reshape it to (H, W, C):\n",
    "tensor_image = tensor_image.view(tensor_image.shape[1], tensor_image.shape[2], tensor_image.shape[0])\n",
    "print(type(tensor_image), tensor_image.shape)\n",
    "\n",
    "plt.imshow(tensor_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mktd-pytorch",
   "language": "python",
   "name": "mktd-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
